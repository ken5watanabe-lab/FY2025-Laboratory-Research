{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5ba82c8-0d3c-43ae-8ae3-331042cbecea",
   "metadata": {},
   "source": [
    "# Estimate sleep State from Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed743ff-bf82-496f-92bd-f6355d948448",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import glob\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "#For Arial font\n",
    "#!conda install -c conda-forge -y mscorefonts\n",
    "##-> The below was also needed in matplotlib 3.4.2\n",
    "#import shutil\n",
    "#import matplotlib\n",
    "#shutil.rmtree(matplotlib.get_cachedir())\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from IPython.display import display\n",
    "import time\n",
    "#For exporting .pdf file with editable text\n",
    "import matplotlib\n",
    "from scipy.stats import mannwhitneyu\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "import scikit_posthocs as sp\n",
    "\n",
    "matplotlib.rcParams['pdf.fonttype']=42\n",
    "matplotlib.rcParams['ps.fonttype']=42\n",
    "import sys\n",
    "from decimal import Decimal, ROUND_HALF_UP\n",
    "import re\n",
    "import os\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "#Create a new conda environment as follows; otherwise, an issue happened (probably due to pip vs. conda)\n",
    "#!conda create --channel=conda-forge --strict-channel-priority --name=mne-py3 -y mne\n",
    "##–> Then, use the mne-py3 kernel\n",
    "import mne\n",
    "from mne.preprocessing import ICA, create_ecg_epochs, find_ecg_events\n",
    "from mne.preprocessing import compute_proj_ecg\n",
    "\n",
    "import scipy.signal as signal\n",
    "\n",
    "#!pip install meegkit\n",
    "#import meegkit\n",
    "\n",
    "#!pip install spkit\n",
    "#import spkit\n",
    "\n",
    "#!conda install -c conda-forge -y gwpy\n",
    "##To avoid the plotting error indcuded by importing gwpy, matplotlib must be downgraded to 3.2.2?\n",
    "#!conda install -c conda-forge -y matplotlib==3.2.2\n",
    "#!pip install matplotlib==3.2.2\n",
    "#import gwpy.timeseries as gpts\n",
    "\n",
    "#!pip install autoreject\n",
    "#import autoreject\n",
    "\n",
    "#!pip install colorcet\n",
    "##-> To avoid \"AttributeError: `np.mat` was removed in the NumPy 2.0 release.\", use the previous version\n",
    "#!pip install numpy==1.26.4\n",
    "from preraulab.multitaper_toolbox.python import multitaper_spectrogram_python as ms\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90aac79-c05d-4492-a38f-8ffc82360bec",
   "metadata": {},
   "source": [
    "> **Warning**  \n",
    "> This project has two incompatible dependencies:  \n",
    "> - MNE-Python requires **Python 3.10 or later**. \n",
    "> - sleepens requires **Python 3.7**.\n",
    ">  \n",
    "> Because these requirements conflict, they cannot be satisfied in a single environment.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4b8dc3bf-1f3e-4dc4-858a-09ec11bd5906",
   "metadata": {},
   "source": [
    "# 1. Prepare data as the mne.io.Raw object\n",
    "memo  \n",
    "以下の内容は予測に過ぎない\n",
    "- .tsp: 動画のフレームの秒数\n",
    "- .dat: eeg, emgが保存されているであろうデータ\n",
    "- .ini, .meta: eeg, emgを保存した際の設定関係の値\n",
    "  \n",
    "---\n",
    "\n",
    ".meta\n",
    "> Number of recorded channels = 12\n",
    "\n",
    ".ini \n",
    "> aiString=0:7  \n",
    "> ChanList4=0, 2, 4, 6, 8, 10, 1, 3, 5, 7, 9, 11, -1, -1, -1, ... , -1  \n",
    "> doCtlChan=0  \n",
    "> doSettleChan=2  \n",
    "> doRECLEDChan=4  \n",
    "> acqPDChan=4  \n",
    "\n",
    "\n",
    "> 1,2 ch 筋電  \n",
    "> 3, 4 ch 頭蓋脳波  \n",
    "> 5, 6 ch 海馬 (HPC)  \n",
    "> 7, 8 ch 一次体性感覚野（S1）  \n",
    "> 9, 10, 11, 12 ch なし（空）\n",
    "---\n",
    "\n",
    "sleep ens\n",
    ">ブレグマから AP +1 mm、ML ±1 mm、およびブレグマから AP -2 mm、ML ±3 mm であった。\n",
    ">前頭骨と頭頂骨の両側に移植した（ブレグマから前方1.5 mm、外側±1.5 mm、後方2 mm、外側±2.75 mm）\n",
    ">\n",
    "## 1-1. load config\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d457d5b8-d584-466f-a32d-c6bad8fc295d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_meta(path):\n",
    "    meta = {}\n",
    "    with open(path, encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            splitter = \" = \"\n",
    "            if not line or splitter not in line:\n",
    "                continue\n",
    "            key, value = map(str.strip, line.split(splitter, 1))\n",
    "            try:\n",
    "                value = float(value)\n",
    "            except ValueError:\n",
    "                value = value\n",
    "            meta[key] = value\n",
    "    return meta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0eb8b6-544a-4e7c-9f36-d1b52784e5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = Path(\"/home/data/sleepStateExperiment_from_video/\")\n",
    "meta_path = Path(DATA_FOLDER, \"20250917-001.meta\")\n",
    "\n",
    "meta = load_meta(meta_path)\n",
    "START_TS = meta[\"TimeStamp of the start of recording (computer clock - ms)\"]\n",
    "END_TS = meta[\"TimeStamp of the end of recording (computer clock - ms)\"]\n",
    "SAMPLING_RATE = int(meta[\"Sampling rate\"])\n",
    "FILE_PATH = Path(meta[\"Filename\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dcde6ff-8105-4e52-810b-7bcdb0667251",
   "metadata": {},
   "source": [
    "## 1-2. load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d11512a-f6c1-44f6-a32d-1fa1e0f249ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_path = Path(DATA_FOLDER, FILE_PATH.name)\n",
    "\n",
    "N_CHANNELS = 12\n",
    "dtype = np.dtype('<i2')  # Little Endian の uint16。合わなければ <i2 に切替\n",
    "\n",
    "array = np.fromfile(dat_path, dtype=dtype)\n",
    "if array.size % N_CHANNELS != 0:\n",
    "    raise Exception(f\"Warning: can't divede with N_CHANNELS. size: {array.size}\")\n",
    "\n",
    "n_frames =array.size // N_CHANNELS\n",
    "data = array.reshape(n_frames, N_CHANNELS)\n",
    "\n",
    "# delete unused channels\n",
    "data = data[:, :8]\n",
    "N_CHANNELS -= 4\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5880ef-738b-4019-8f8d-26a611b5b2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check array when Error( Warning: can't divede with N_CHANNELS) occured\n",
    "dat_path = Path(DATA_FOLDER, FILE_PATH.name)\n",
    "\n",
    "N_CHANNELS = 12\n",
    "dtype = np.dtype('<i2')  # Little Endian の uint16。合わなければ <i2 に切替\n",
    "\n",
    "array = np.fromfile(dat_path, dtype=dtype)\n",
    "array = array[ : array.size // N_CHANNELS * N_CHANNELS]\n",
    "n_frames =array.size // N_CHANNELS\n",
    "data = array.reshape(n_frames, N_CHANNELS)\n",
    "\n",
    "# delete unused channels\n",
    "data = data[:, :8]\n",
    "N_CHANNELS -= 4\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a938c8-16c6-4849-875d-25a618ac081d",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b34b4785-4b69-401e-bca9-7e2d6977109a",
   "metadata": {},
   "source": [
    "## 1-3. convert to V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6404f167-09bc-42d4-9abd-1cb29241959e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data is to large to run following,\n",
    "# data = data.astype(np.float16)/(1 << 15) * 5 / (10 ** 3)\n",
    "# hence, use chunk\n",
    "# TODO: is it better to use float32?\n",
    "chunk = 50_000_000\n",
    "scale = np.float16(1 << 15)\n",
    "data_v = np.empty_like(data, dtype=np.float16)\n",
    "for start in range(0, data.size, chunk):\n",
    "    end = min(start + chunk, data.size)\n",
    "    tmp_data = data[start:end].astype(np.float16)\n",
    "    tmp_data = tmp_data / scale * 5 / (10 ** 3)\n",
    "    data_v[start:end] = tmp_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c99a851-7d75-4f8a-a962-9a73884cd0d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tmp = data_v[1500000:2000000]\n",
    "for i in range(8):\n",
    "    plt.figure(figsize=(10, 3))\n",
    "    plt.plot(tmp[:, i])\n",
    "    plt.title(f\"Channel {i}\")\n",
    "    plt.xlabel(\"Index\")\n",
    "    plt.ylabel(\"Value\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5bd3da-c9db-4d33-bbe8-9f2c9e852352",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "567d9e12-3ddf-42bc-b7d8-e081572b73aa",
   "metadata": {},
   "source": [
    "## 1-4 create mne.io.Raw object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3dc9e0-b513-496b-90f5-ea19566f907d",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHANNEL_NAMES = [\n",
    "    \"EMG-1\", \"EMG-2\",\n",
    "    \"Skull-1\", \"Skull-2\",\n",
    "    \"HPC-1\", \"HPC-2\",\n",
    "    \"S1-1\", \"S1-2\"\n",
    "]\n",
    "CHANNEL_TYPES = [\"emg\"] * 2 + [\"eeg\"] * 6\n",
    "bad_channels = []\n",
    "\n",
    "# create an mne.Info object\n",
    "mneInfo = mne.create_info(CHANNEL_NAMES, SAMPLING_RATE, ch_types=CHANNEL_TYPES)\n",
    "\n",
    "# Set bad channels\n",
    "mneInfo[\"bads\"] = bad_channels\n",
    "\n",
    "display(mneInfo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dba90ba-7616-49f7-ba9f-b8b4918f3656",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an mne.io.Raw object\n",
    "print('Original np.array:', data_v.shape)\n",
    "\n",
    "#Transpose the table\n",
    "tempA = data_v.transpose()\n",
    "\n",
    "#Select the target subject\n",
    "tempA = tempA[:]\n",
    "print('-> After transpose and selection:', tempA.shape)\n",
    "\n",
    "#Convert to the default unit\n",
    "# tempA = tempA / (10**6)#From uV to V\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f621d8-3886-40b1-aeed-54670b473ace",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # with lots of memory, we can use this code\n",
    "# # or no split needed if memory is sufficient.\n",
    "\n",
    "# # #Create an mne.io.Raw \n",
    "# MNE_DIR = Path(DATA_FOLDER, \"mneRaw\")\n",
    "# n_t = tempA.shape[1]\n",
    "\n",
    "# # separate with (55 minutes 30 sec) * 3 . this value almost corresponds to 2GB(mne limit) * 3\n",
    "# # this separation is due to memory crash\n",
    "# seg_len = SAMPLING_RATE * (60 * 55 + 30) * 3\n",
    "# seg_len = min(seg_len, n_t)\n",
    "\n",
    "# raw_written = False\n",
    "# for part, start in enumerate(range(0, n_t, seg_len)):\n",
    "#     end = min(start + seg_len, n_t)\n",
    "\n",
    "#     seg = np.ascontiguousarray(tempA[:, start:end], dtype=np.float32)\n",
    "\n",
    "#     raw = mne.io.RawArray(seg, mneInfo, first_samp=start)\n",
    "\n",
    "#     # f_path = Path(MNE_DIR, f\"{FILE_PATH.stem}{f'-{part}' if part > 0 else ''}.fif\")\n",
    "#     f_path = Path(MNE_DIR, f\"{FILE_PATH.stem}-{part}.fif\")\n",
    "#     raw.save(f_path, overwrite=True)\n",
    "#     print(f\"Saved {f_path}\")\n",
    "\n",
    "#     del raw, seg\n",
    "#     gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd17f984-a3ab-4155-80fe-d806cf6407cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def rows_for_2gb_segment(\n",
    "    n_ch: int,\n",
    "    sampling_rate: int,\n",
    "    write_dtype: np.dtype = np.dtype(np.float32),\n",
    "    target_bytes: int = 2 * 1024**3,\n",
    "    header_margin: int = 16 * 1024**2,\n",
    "    round_sec: int = 5,\n",
    ") -> int:\n",
    "\n",
    "    # bytes per round_sec\n",
    "    dtype_size = write_dtype.itemsize\n",
    "    bytes_per_row = n_ch * dtype_size\n",
    "    bytes_per_round_sec = bytes_per_row * int(sampling_rate * round_sec)\n",
    "\n",
    "    # effective size budget (avoid header/metadata overhead)\n",
    "    effective_max = target_bytes - header_margin\n",
    "\n",
    "    # max rows that fit in the budget\n",
    "    max_round_sec = effective_max // bytes_per_round_sec\n",
    "    max_rows = max_round_sec * int(sampling_rate * round_sec)\n",
    "\n",
    "    return max_rows\n",
    "\n",
    "\n",
    "WRITE_DTYPE = np.float32  # recommended by mne\n",
    "MNE_DIR = Path(DATA_FOLDER, \"mneRaw\")\n",
    "n_ch, n_t = tempA.shape\n",
    "\n",
    "# row length per file\n",
    "seg_len = rows_for_2gb_segment(n_ch, SAMPLING_RATE)\n",
    "\n",
    "# save\n",
    "for part, start in enumerate(range(0, n_t, seg_len)):\n",
    "    end = min(start + seg_len, n_t)\n",
    "\n",
    "    seg = np.ascontiguousarray(tempA[:, start:end], dtype=WRITE_DTYPE)\n",
    "\n",
    "    raw = mne.io.RawArray(seg, mneInfo, first_samp=start)\n",
    "\n",
    "    f_path = Path(MNE_DIR, f\"{FILE_PATH.stem}-{part}.fif\")\n",
    "    raw.save(f_path, overwrite=True, fmt=\"single\") # single means float32. defaults to single\n",
    "    print(f\"Saved {f_path}  |  samples={seg.shape[1]}  seconds≈{seg.shape[1]/SAMPLING_RATE:.1f}\")\n",
    "\n",
    "    del raw, seg\n",
    "    gc.collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b5a96c-6e1d-4aa7-bb35-268720f5ca79",
   "metadata": {},
   "source": [
    "# 2. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa666e9-020d-42e9-a755-604d77a268c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mneR = mne.io.read_raw_fif(\n",
    "#     Path(MNE_DIR, FILE_PATH.with_suffix(\".fif\").name), preload=False\n",
    "# )\n",
    "\n",
    "mneR = mne.io.read_raw_fif(\n",
    "    # to develop faster, use small file.\n",
    "    # Path(DATA_FOLDER, \"mneRaw\", \"20250917-001-0.fif\")\n",
    "    Path(DATA_FOLDER, \"mneRaw\", \"20250917-001-3.fif\")\n",
    ")\n",
    "mneI = mneR.info.copy()\n",
    "mneR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fceb1f3-4d08-4c0e-bd78-46b0039ae3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_psdPlot(legends, raws):\n",
    "    f_min, f_max = 0, 200#Target frequency [Hz]\n",
    "    t_min, t_max = 600, 610#Target time range [sec]\n",
    "    picks = [\"eeg\", \"emg\"]\n",
    "    sns.set(style='ticks', context='notebook')\n",
    "    for title, data in zip(legends, raws):\n",
    "        psd = mneR.compute_psd(method='multitaper', fmin=f_min, fmax=f_max, tmin=t_min, tmax=t_max, picks=picks)\n",
    "        fig = psd.plot(picks=picks, exclude=\"bads\", amplitude=False, average=False, dB=True)\n",
    "        fig.suptitle(title, size='xx-large', weight='bold')\n",
    "    # scalling = dict(eeg=500e-3, emg=500e-3)\n",
    "    # for data in raws:\n",
    "    #     fig = data.plot(duration=1, n_channels=8, scalings=scalling)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508d1dd1-69e9-4bba-8277-2b0606dd1421",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_psdPlot([\"Original\"], [mneR])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495c6fea-c46a-41b0-89a6-7cc9e5b09489",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_waveforms(raw, title_text=\"\", span=(0, -1), unit=\"sec\"):\n",
    "    \"\"\"\n",
    "    Display waveform traces for each channel in an MNE Raw object.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    raw : mne.io.Raw\n",
    "        MNE Raw with time-series data.\n",
    "    title_text : str, optional\n",
    "        Title displayed on the first subplot.\n",
    "    span : tuple (start, end), optional\n",
    "        Time range to plot. Interpreted in seconds if unit=\"sec\",\n",
    "        or in minutes if unit=\"min\". Default (0, -1) means full range.\n",
    "    unit : {\"sec\", \"min\"}, optional\n",
    "        Controls x-axis conversion and downsampling policy.\n",
    "        - \"sec\": no downsampling (native sampling)\n",
    "        - \"min\": downsample to 1/60 (keep every 60th sample) and x-axis in minutes\n",
    "    \"\"\"\n",
    "\n",
    "    # -------- Settings & inputs --------\n",
    "    if unit not in {\"sec\", \"min\"}:\n",
    "        raise ValueError(\"unit must be one of {'sec', 'min'}\")\n",
    "\n",
    "    sfreq = float(raw.info[\"sfreq\"])  # samples per second\n",
    "    start, end = span\n",
    "\n",
    "    # -------- Resolve time window (always slice in seconds) --------\n",
    "    # Interpret span according to unit, then convert to seconds for slicing\n",
    "    if start is None:\n",
    "        start = 0.0\n",
    "    if end is None:\n",
    "        end = -1\n",
    "\n",
    "    if unit == \"min\":\n",
    "        # Convert minutes to seconds for indexing\n",
    "        start_sec = float(start) * 60.0 if start not in (0, -1) else float(start if start != 0 else 0.0)\n",
    "        end_sec = float(end) * 60.0 if end not in (0, -1) else float(end)\n",
    "    else:  # unit == \"sec\"\n",
    "        start_sec = float(start) if start not in (0, -1) else float(start if start != 0 else 0.0)\n",
    "        end_sec = float(end)\n",
    "\n",
    "    # Handle \"-1\" as \"till the end\"\n",
    "    if end_sec == -1:\n",
    "        end_sec = raw.times[-1]\n",
    "    # Clip to valid interval\n",
    "    start_sec = max(start_sec, raw.times[0])\n",
    "    end_sec = min(end_sec, raw.times[-1])\n",
    "\n",
    "    # Convert time window to sample indices\n",
    "    start_idx, end_idx = raw.time_as_index([start_sec, end_sec])\n",
    "\n",
    "    # -------- Load data (slice first at native rate) --------\n",
    "    data = raw.get_data()[:, start_idx:end_idx]  # shape: (n_ch, n_times)\n",
    "    times_sec = raw.times[start_idx:end_idx]\n",
    "\n",
    "    # -------- Unit-dependent x-axis conversion & downsampling --------\n",
    "    # For \"min\": keep every 60th sample (1/60 downsampling) and convert x to minutes\n",
    "    if unit == \"min\":\n",
    "        step = max(1, int(60))  # keep every 60th sample; safeguard for very short segments\n",
    "        data = data[:, ::step]\n",
    "        times = (times_sec[::step] / 60.0)  # seconds -> minutes for x-axis\n",
    "        x_label = 'Time [min]'\n",
    "    else:\n",
    "        # \"sec\": no downsampling, x-axis remains in seconds\n",
    "        times = times_sec\n",
    "        x_label = 'Time [sec]'\n",
    "\n",
    "    # -------- Plot (unchanged) --------\n",
    "    sns.set(style='ticks', context='notebook')\n",
    "    n_ch = raw.info[\"nchan\"]\n",
    "\n",
    "    fig, axes = plt.subplots(\n",
    "        nrows=n_ch, ncols=1,\n",
    "        figsize=(10, max(2, n_ch / 2)),\n",
    "        sharex=True, sharey=True,\n",
    "        gridspec_kw={'height_ratios': [1] * n_ch, 'hspace': 0.0}\n",
    "    )\n",
    "\n",
    "    if n_ch == 1:\n",
    "        axes = [axes]\n",
    "\n",
    "    # Axis limits (based on converted times and sliced data)\n",
    "    xlim = (times[0], times[-1]) if times.size else (0, 0)\n",
    "    ylim = (data.min() if data.size else -1, data.max() if data.size else 1)\n",
    "    plt.setp(axes, xlim=xlim, ylim=ylim)\n",
    "\n",
    "    for ax_i, ax in enumerate(axes):\n",
    "        # Plot waveform (x is in sec or min depending on unit)\n",
    "        ax.plot(times, data[ax_i], color='k', linewidth=0.25)\n",
    "\n",
    "        # Clean axes\n",
    "        ax.spines.top.set_visible(False)\n",
    "        ax.spines.right.set_visible(False)\n",
    "        plt.setp(ax.get_yticklabels(), visible=False)\n",
    "        ax.set_yticks([])\n",
    "\n",
    "        if ax_i == n_ch - 1:\n",
    "            ax.set_xlabel(x_label)  # ← keep as-is per your request (do not touch plot features)\n",
    "        else:\n",
    "            ax.spines.bottom.set_visible(False)\n",
    "            ax.get_xaxis().set_visible(False)\n",
    "\n",
    "        # Channel label on the right\n",
    "        ax.set_ylabel(\n",
    "            raw.ch_names[ax_i],\n",
    "            rotation=0,\n",
    "            horizontalalignment='right',\n",
    "            verticalalignment='center',\n",
    "            rotation_mode='anchor'\n",
    "        )\n",
    "\n",
    "        # Title on the first subplot\n",
    "        if ax_i == 0 and title_text:\n",
    "            ax.set_title(title_text)\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0e123a-81d8-4f24-b186-c133389f8bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_text = f'Subject: {None}, Condition: {None}, Trial: {None} — LFP waveform (full range)'\n",
    "display_waveforms(mneR, title_text, unit=\"min\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ec05ae-ea84-4576-82dc-a91d4775df5c",
   "metadata": {},
   "source": [
    "## 2-1. Detrending\n",
    "Detrending can be interpreted as substracting a least squares fit polyonimial.  \n",
    "\n",
    "\n",
    "this part is included in sleepen. see [function process](https://github.com/paradoxysm/sleepens/blob/master/sleepens/protocols/sleepens4/processor.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377f6916-f986-40e3-99e0-addb5de52170",
   "metadata": {},
   "source": [
    "### 2-1-1. Detrending by myself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730a83a9-1a41-4b62-9638-d00816f12a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "print('Before:')\n",
    "display(mneR.describe())\n",
    "\n",
    "#Remove linear trend along axis\n",
    "tempA = signal.detrend(mneR.get_data().T, axis=0, type='linear', bp=np.arange(0, mneR.n_times, SAMPLING_RATE))\n",
    "mneR_dt = mne.io.RawArray(tempA.T, mneI)\n",
    "print('After:')\n",
    "display(mneR_dt.describe())\n",
    "\n",
    "display(mneR_dt.get_data())#Changed unit: uV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5aab3b-3b01-46c9-a522-a2c66fc615a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_waveforms(mneR_dt, unit=\"min\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c69e1cd-3698-453a-8187-77e26ce825aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_psdPlot([\"Raw\", \"Detrended\"], [mneR, mneR_dt])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f7780b-b1dd-4efc-9e17-a4cf59b72ce8",
   "metadata": {},
   "source": [
    "### 2-1-2. Detrending by sleepens\n",
    "this part is in `python/sleepens/detrend.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c90018-d970-4121-871d-2a13d0bcb3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "mneR_temp = mne.io.read_raw_fif(\n",
    "    Path(DATA_FOLDER, \"mneRaw_detrend\", \"20250917-001-3.fif\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7faa4dbb-865c-4bcb-9c9a-71edeb29a63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_waveforms(mneR_temp, unit=\"min\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dfd4fa2-2398-482f-8652-653c2816bb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_psdPlot([\"Raw\", \"Detrended\"], [mneR, mneR_temp])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510a7e1d-ddd5-4cdd-8b25-1b8c26beffcd",
   "metadata": {},
   "source": [
    "## 2-2. Remove DC component(i.e., 0 Hz noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7529b6c2-e21a-4e7d-ab6c-52d8ac2a276f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#Calculate the DC components per channel from all samples\n",
    "data = mneR_dt.get_data()\n",
    "tempS = data.mean(axis=1, keepdims=True)\n",
    "print('DC components:')\n",
    "display(tempS)\n",
    "\n",
    "#Subtract them from the original raw data\n",
    "print('Before:')\n",
    "display(mneR_dt.describe())\n",
    "\n",
    "data -= tempS\n",
    "\n",
    "#Re-create an mne.io.Raw object\n",
    "mneR_dc = mne.io.RawArray(data, mneI, first_samp=0, copy='auto')\n",
    "\n",
    "print('After:')\n",
    "display(mneR_dc.describe())\n",
    "display(mneR_dc.get_data())#Changed unit: uV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a1577b-6bcb-457e-9515-b7b7f1fac985",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_waveforms(mneR_dc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d27b0f8-4cfc-4931-92a1-5edb69d3d8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_psdPlot([ \"Detrended\", \"DC-removed\"], [mneR_dt, mneR_dc])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5fbb6e8-c634-4877-8da0-753bc052640a",
   "metadata": {},
   "source": [
    "## ~~2-3. Eliminate the power line noises using MEEGkit~~\n",
    "\n",
    "Utilize a Denoising Source Separation (DSS) technique: Zapline paper (de Cheveigné, A. Neuroimage 2020).  \n",
    "> meegkit.dss.dss_line_iter():  \n",
    "> Remove power line artifact iteratively. This method applies dss_line() until the artifact has been smoothed out from the spectrum.  \n",
    "> Parameters  \n",
    "> * data : data, shape=(n_samples, n_chans, n_trials)  \n",
    "Input data.  \n",
    "> * fline : float  \n",
    "> Line frequency.  \n",
    "> * sfreq : float  \n",
    "> Sampling frequency.  \n",
    "> * win_sz : float  \n",
    "> Half of the width of the window around the target frequency used to fit the polynomial (default=10).  \n",
    "> * spot_sz : float  \n",
    "> Half of the width of the window around the target frequency used to remove the peak and interpolate (default=2.5).  \n",
    "> * nfft : int  \n",
    "> FFT size for the internal PSD calculation (default=512).  \n",
    "> * show: bool  \n",
    "> Produce a visual output of each iteration (default=False).  \n",
    "> * prefix : str  \n",
    "> Path and first part of the visualisation output file \"{prefix}\\_{iteration number}.png\" (default=\"dss_iter\").  \n",
    "> * n_iter_max : int  \n",
    "> Maximum number of iterations (default=100).  \n",
    ">\n",
    "> Returns  \n",
    "> * data : array, shape=(n_samples, n_chans, n_trials)  \n",
    "> Denoised data.  \n",
    "> * iterations : int  \n",
    "> Number of iterations.  \n",
    "\n",
    "To increase the computational speed, the overall data is split into dummy windows/epochs/trials while discarding the last remainder samples. Note that the splitting method doesn't matter because the power line noises were constantly observed during recordings.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20eda34f-40e7-4bce-b6c0-9cf323baa79d",
   "metadata": {},
   "source": [
    "> ***–> Skip in this version!***  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0cd6e2-96dc-44c5-bd94-7f4a7b627ea8",
   "metadata": {},
   "source": [
    "## ~~2-4. ATAR algorithm~~\n",
    "Automatic and Tunable Artifact Removal (ATAR) algorithm (Bajaj, N. et al. Biomed. Signal Process. Control 2020) is used to remove artifacts. This algorithm is based on wavelet packet decomposion (WPD), and provided by the Python spkit package (https://spkit.github.io/guide/index.html).  \n",
    "> - Docs: https://spkit.readthedocs.io/en/latest/index.html  \n",
    "> - Post about ICA vs. ATAR: https://medium.com/@nikeshbajaj/artifacts-in-eeg-and-how-to-remove-them-atar-algorithm-ica-fbb91ea8485a  \n",
    "> - GitHub: https://github.com/Nikeshbajaj/spkit  \n",
    "\n",
    "    ATAR_mCh  \n",
    "    ========================================================\n",
    "    Apply ATAR on short windows of signal (multiple channels:):\n",
    "\n",
    "    Signal is decomposed in smaller overlapping windows and reconstructed after correcting using overlap-add method.\n",
    "    ----------------\n",
    "\n",
    "    input\n",
    "    -----\n",
    "    X: input multi-channel signal of shape (n,ch)\n",
    "\n",
    "    Wavelet family:\n",
    "    wv = ['db3'.....'db38', 'sym2.....sym20', 'coif1.....coif17', 'bior1.1....bior6.8', 'rbio1.1...rbio6.8', 'dmey']\n",
    "         :'db3'(default)\n",
    "\n",
    "    Threshold Computation method:\n",
    "    thr_method : None (default), 'ipr'\n",
    "           : None: fixed threshold theta_a is applied\n",
    "           : ipr : applied with theta_a, bf , gf, beta, k1, k2 and OptMode\n",
    "           : theta_b = bf*theta_a\n",
    "           : theta_g = gf*theta_a\n",
    "\n",
    "    Operating modes:\n",
    "    OptMode = ['soft','elim','linAtten']\n",
    "             : default 'soft'\n",
    "             : use 'elim' with globalgood\n",
    "\n",
    "    Wavelet Decomposition modes:\n",
    "    wpd_mode = ['zero', 'constant', 'symmetric', 'periodic', 'smooth', 'periodization']\n",
    "                default 'symmetric'\n",
    "\n",
    "    Reconstruction Method - Overlap-Add method\n",
    "    ReconMethod :  None, 'custom', 'HamWin'\n",
    "    for 'custom': window[0] is used and applied after denoising is window[1] is True else\n",
    "    windowing applied before denoising\n",
    "\n",
    "    output\n",
    "    ------\n",
    "    XR: corrected signal of same shape as input X\n",
    "    '''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a56a9d77-1143-40b3-9c69-b4f81879bf27",
   "metadata": {},
   "source": [
    "> ***–> Skip in this version!*** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adaa5016-ac60-4cd8-a79e-416b8b552018",
   "metadata": {},
   "source": [
    "## 2-5. Notch filter\n",
    "remove AC noise(50Hz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace89b43-aed7-4107-a2bf-a80188f00ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Before: \")\n",
    "display(mneR_dc.describe())\n",
    "mneR_notch = mneR_dc.notch_filter(\n",
    "    freqs=50,                # 自動検出\n",
    "    picks=[\"eeg\", \"emg\"],\n",
    "    method=\"spectrum_fit\",\n",
    "    filter_length=\"10s\",       # 推定安定化\n",
    "    mt_bandwidth=3.0,          # マルチテーパー帯域幅\n",
    "    p_value=0.05\n",
    ")\n",
    "print(\"After: \")\n",
    "display(mneR_notch.describe())\n",
    "mneR_notch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4e41f6-c776-4519-a102-d3a296d4f946",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_waveforms(mneR_notch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67bad11-bda8-4f93-9bc3-81f76625b5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_psdPlot([\"DC-removed\", \"notch-50 Hz\"], [mneR_dc, mneR_notch])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e958872-b1c6-44d4-8048-c5e31516f12e",
   "metadata": {},
   "source": [
    "## ~~2-6. ecg filter~~\n",
    "\n",
    "filtering heart beats noise from EMG\n",
    "using [SSP approach](https://mne.tools/stable/auto_tutorials/preprocessing/50_artifact_correction_ssp.html#sphx-glr-auto-tutorials-preprocessing-50-artifact-correction-ssp-py).  \n",
    "ICA approach is impossible because emg has only 2 channels.\n",
    "\n",
    "> ***–> Skip in this version!***\n",
    "\n",
    "In this part, we only applied it to EMG, but since some noise can be seen in EEG, it may be possible to apply it to EEG as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029d2898-3bd8-49ea-9bf8-3f0cf219fb57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import mne\n",
    "# from mne.preprocessing import find_ecg_events\n",
    "\n",
    "# # --- 0) I/O handles ---\n",
    "# raw = mneR_notch.copy()  # if you already applied notch elsewhere, keep consistent\n",
    "# emg_ch = 'EMG-1'         # EMG channel with strong ECG contamination\n",
    "\n",
    "# # --- 1) (Optional but recommended) Notch to suppress power-line harmonics on the DETECTION COPY ---\n",
    "# # If your region is 50 Hz: use np.arange(50, 251, 50); if 60 Hz: np.arange(60, 301, 60)\n",
    "# line = 50  # or 60 depending on region\n",
    "# raw_det = raw.copy()  # .notch_filter(freqs=np.arange(line, 6*line+1, line),\n",
    "#                                  # picks=[emg_ch], method='spectrum_fit')\n",
    "\n",
    "# # --- 2) (Optional) Light band-pass to emphasize QRS for detection only ---\n",
    "# raw_det.filter(5., 35., picks=[emg_ch], phase='zero', verbose=False)\n",
    "\n",
    "# # --- 3) Detect R-peaks on the detection copy using the EMG channel as pseudo-ECG ---\n",
    "# events, _, average_pulse, ecg_by_mne = find_ecg_events(raw_det, ch_name=emg_ch, event_id=999, return_ecg=True)\n",
    "# if len(events) == 0:\n",
    "#     raise RuntimeError(\"No ECG-like events detected on the EMG channel\")\n",
    "# print(f\"average ecg pulse: {average_pulse}\")\n",
    "# print(events)\n",
    "# # --- 4) Build epochs on the ORIGINAL (broadband) raw so that removal works across all frequencies ---\n",
    "# tmin, tmax = -0.2, 0.4  # seconds around R\n",
    "# epochs = mne.Epochs(raw, events, event_id=999, tmin=tmin, tmax=tmax,\n",
    "#                     picks=[emg_ch], baseline=(None, 0), preload=True,\n",
    "#                     reject=None, reject_by_annotation=False)\n",
    "# if len(epochs) == 0:\n",
    "#     raise RuntimeError(\"Epochs are empty; check event_id/tmin-tmax/annotations\")\n",
    "\n",
    "# # --- 5) Average template (Evoked) and extract ndarray waveform ---\n",
    "# template = epochs.average(picks=[emg_ch]).data[0]  # ndarray, shape=(n_times,)\n",
    "\n",
    "# # --- 6) Overlap-add to reconstruct ECG-like trace over the full recording (broadband estimate) ---\n",
    "# sfreq = raw.info['sfreq']\n",
    "# n_times = raw.n_times\n",
    "# n_temp = len(template)\n",
    "# offset = int(round(-tmin * sfreq))\n",
    "# ecg_est = np.zeros(n_times, dtype=np.float64)\n",
    "\n",
    "# for ev in events[:, 0]:\n",
    "#     start = ev - offset\n",
    "#     end = start + n_temp\n",
    "#     s0 = max(start, 0); e0 = min(end, n_times)\n",
    "#     ts = s0 - start; te = n_temp - (end - e0)\n",
    "#     if s0 < e0:\n",
    "#         ecg_est[s0:e0] += template[ts:te]\n",
    "\n",
    "# # --- 7a) (Option A) Add estimated ECG as a new channel (for inspection/regression later) ---\n",
    "# ecg_data = np.vstack([ecg_est, ecg_by_mne]).astype('float64')  # shape: (2, n_times)\n",
    "# info = mne.create_info(['ECG_by_TS', 'ECG_by_MNE'], sfreq=raw.info['sfreq'], ch_types=['ecg', 'ecg'])\n",
    "# raw_ecg = mne.io.RawArray(ecg_data, info)\n",
    "# mneR_with_ecg = raw.copy().add_channels([raw_ecg], force_update_info=True)\n",
    "\n",
    "# # --- 7b) (Option B) Direct template subtraction on the EMG channel to remove ECG across ALL bands ---\n",
    "# #       This realizes broadband removal because template/placement are made on the original raw.\n",
    "# emg_idx = mne.pick_channels(raw.ch_names, [emg_ch])[0]\n",
    "# raw_broadband_clean = raw.copy()\n",
    "# raw_broadband_clean._data[emg_idx, :] -= ecg_est  # subtract artifact estimate\n",
    "\n",
    "\n",
    "# def remove_ecg_from_emg(raw):\n",
    "#     # filter ecg from emg\n",
    "#     raw_emg = raw.copy().pick(\"emg\")\n",
    "#     raw_ecg = raw_emg.copy()\n",
    "#     raw_emg_ch_names = raw_emg.ch_names.copy()\n",
    "\n",
    "#     # temporary treat as eeg.\n",
    "#     raw_emg.set_channel_types(\n",
    "#         {ch: 'eeg' for ch in raw_emg_ch_names}\n",
    "#     )\n",
    "#     # # use emg as ecg\n",
    "#     raw_ecg.set_channel_types(\n",
    "#         {ch: 'ecg' for ch in raw_emg_ch_names}\n",
    "#     )\n",
    "#     ecg_ch_names = [f\"{i}-ecg\" for i in raw_emg_ch_names]\n",
    "#     raw_ecg.rename_channels({i: f\"{i}-ecg\" for i in raw_emg_ch_names})\n",
    "#     raw_emg.add_channels([raw_ecg], force_update_info=True)\n",
    "\n",
    "\n",
    "#     projs, events = compute_proj_ecg(raw_emg, n_grad=0, n_mag=0, n_eeg=2)\n",
    "#     raw_emg.add_proj(projs)\n",
    "#     raw_emg_clean = raw_emg.copy().apply_proj()\n",
    "\n",
    "#     # Restore channel types back to EMG\n",
    "#     raw_emg_clean.set_channel_types(\n",
    "#         {ch: \"emg\" for ch in raw_emg_clean.ch_names}\n",
    "#     )\n",
    "\n",
    "#     # Merge back with original raw\n",
    "#     raw_no_emg = raw.copy().drop_channels(raw_emg_ch_names)\n",
    "#     raw_emg_clean.drop_channels(ecg_ch_names)\n",
    "#     raw_out = raw_emg_clean.add_channels([raw_no_emg], force_update_info=True)\n",
    "\n",
    "#     return raw_out\n",
    "\n",
    "\n",
    "# def remove_ecg_from_emg(raw):\n",
    "\n",
    "#     raw = raw.copy()\n",
    "#     raw_ecg = raw.copy()\n",
    "#     raw_emg_ch_names = raw.copy().pick(\"emg\").ch_names.copy()\n",
    "\n",
    "#     # temporary treat as eeg.\n",
    "#     raw.set_channel_types(\n",
    "#         {ch: 'eeg' for ch in raw.ch_names}\n",
    "#     )\n",
    "#     # # use as ecg\n",
    "#     raw_ecg.set_channel_types(\n",
    "#         {ch: 'ecg' for ch in raw.ch_names}\n",
    "#     )\n",
    "#     ecg_ch_names = [f\"{i}-ecg\" for i in raw.ch_names]\n",
    "#     raw_ecg.rename_channels({i: f\"{i}-ecg\" for i in raw.ch_names})\n",
    "#     raw.add_channels([raw_ecg], force_update_info=True)\n",
    "\n",
    "\n",
    "#     projs, events = compute_proj_ecg(raw, n_grad=0, n_mag=0, n_eeg=2)\n",
    "#     raw.add_proj(projs)\n",
    "#     raw_clean = raw.copy().apply_proj()\n",
    "\n",
    "#     # Restore channel types back to EMG\n",
    "#     raw_clean.set_channel_types(\n",
    "#         {ch: \"emg\" for ch in raw_emg_ch_names}\n",
    "#     )\n",
    "\n",
    "#     # Merge back with original raw\n",
    "#     raw_clean.drop_channels(ecg_ch_names)\n",
    "\n",
    "#     return raw_clean\n",
    "\n",
    "\n",
    "# mneR_ecg = remove_ecg_from_emg(mneR_notch)\n",
    "# mneR_ecg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea4dd7ef-7286-4f73-b1e6-ccf0bd4df8bc",
   "metadata": {},
   "source": [
    "## 2-7. Band-pass filter\n",
    "Use a eighth order zero phase lag Butterworth filter.  \n",
    "\n",
    "In [A novel machine learning system for identifying sleep–wake states in mice](https://academic.oup.com/sleep/article/46/6/zsad101/7109541), they used between 0.3 and 100 Hz for EEG, between 30 and 30k Hz for EMG.\n",
    "For now, use between 0.3 and 100 Hz for EEG and between 30 and 9999 Hz for EMG.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aba12b5-cb65-46e7-8fad-22e3cceae110",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Before:\")\n",
    "print(mneR_notch.describe())\n",
    "\n",
    "# Preapre an IIR filter\n",
    "EEG_D = mne.filter.construct_iir_filter(\n",
    "    iir_params=dict(order=8, ftype='butter', output='sos'),\n",
    "    f_pass=[0.3, 120],\n",
    "    f_stop=None,  # Not used if ‘order’ is specified in iir_params\n",
    "    sfreq=SAMPLING_RATE,\n",
    "    btype='bandpass',\n",
    "    phase='zero',\n",
    "    return_copy=False\n",
    ")\n",
    "EMG_D = mne.filter.construct_iir_filter(\n",
    "    iir_params=dict(order=8, ftype='butter', output='sos'),\n",
    "    f_pass=[30, 9999],\n",
    "    f_stop=None,  # Not used if ‘order’ is specified in iir_params\n",
    "    sfreq=SAMPLING_RATE,\n",
    "    btype='bandpass',\n",
    "    phase='zero',\n",
    "    return_copy=False\n",
    ")\n",
    "# Filter data\n",
    "mneR_butter = mneR_notch.copy().filter(\n",
    "    l_freq=None, h_freq=None,  # For FIR filter\n",
    "    picks=\"eeg\",  # All channels\n",
    "    filter_length='auto',  # For FIR filter\n",
    "    l_trans_bandwidth='auto', h_trans_bandwidth='auto',  # For FIR filter\n",
    "    n_jobs=None,  # For FIR filter\n",
    "    method='iir',\n",
    "    iir_params=EEG_D,\n",
    "    phase='zero',\n",
    "    fir_window='hamming', fir_design='firwin',  # For FIR filter\n",
    "    skip_by_annotation=('edge', 'bad_acq_skip'),\n",
    "    pad='reflect_limited',  # For FIR filter\n",
    "    verbose=None\n",
    ")\n",
    "mneR_butter = mneR_butter.filter(\n",
    "    l_freq=None, h_freq=None,  # For FIR filter\n",
    "    picks=\"emg\",  # All channels\n",
    "    filter_length='auto',  # For FIR filter\n",
    "    l_trans_bandwidth='auto', h_trans_bandwidth='auto',  # For FIR filter\n",
    "    n_jobs=None,  # For FIR filter\n",
    "    method='iir',\n",
    "    iir_params=EMG_D,\n",
    "    phase='zero',\n",
    "    fir_window='hamming', fir_design='firwin',  # For FIR filter\n",
    "    skip_by_annotation=('edge', 'bad_acq_skip'),\n",
    "    pad='reflect_limited',  # For FIR filter\n",
    "    verbose=None\n",
    ")\n",
    "print(\"After: \")\n",
    "display(mneR_butter.describe())\n",
    "display(mneR_butter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587b666d-a175-4fcf-8ddf-38c17e02fcce",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_waveforms(mneR_butter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b2a0be-77b9-4058-b99b-e7ac313abe23",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_psdPlot([\"notch-50 Hz\", \"Butterworth\"], [mneR_notch, mneR_butter])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "720e6dcf-12e1-4076-be2c-0e2ba00669f7",
   "metadata": {},
   "source": [
    "## ~~2-8. Spectral whitening~~\n",
    "> *\"A whitening transformation or sphering transformation is a linear transformation that transforms a vector of random variables with a known covariance matrix into a set of new variables whose covariance is the identity matrix, meaning that they are uncorrelated and each have variance 1\"* (Wikipedia).  \n",
    "\n",
    "In signal processing, it usually means a transformation to generate flat Fourier spectrum for a given signal, which is originally colored (not white). This processing tends to sharpen signal, as well as the noise. The whitening process is often used for ambient vibration data before stacking waveforms for cross-correlation.  \n",
    "> - The Dr. Takeuchi's code (mtspectrumc_whiten.m) just multiplies amplitude/power by frequency (after FFT)... It would surely reduce lower frequency, but it changes the unit, doesn't it!?  \n",
    "> - The MATLAB whitening function (https://www.mathworks.com/matlabcentral/fileexchange/65345-spectral-whitening) process is simple as Fourier transforming the signal after applying Hann window, then normalizing its magnitude, and then inverse Fourier transforming it. The normalization is forcedly setting magnitudes (within the range) with 1.  \n",
    "\n",
    "–> After searching, I found that GWpy (a signal processing package for gravitational-wave detectors; https://gwpy.github.io/docs/stable/) contains spectral whitening function. Based on its source code, it normalizes the Fourier spectrum by a convolution with a whitening filter (i.e., multiplying the inverse of amplitude). So, it would be applicable to EEG data!  \n",
    "> - Tutorial: https://gwpy.github.io/docs/stable/examples/timeseries/whiten/  \n",
    "> - Function: https://gwpy.github.io/docs/stable/api/gwpy.timeseries.TimeSeries/#gwpy.timeseries.TimeSeries.whiten  \n",
    "\n",
    "        \"\"\"Whiten this `TimeSeries` using inverse spectrum truncation  \n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        fftlength : `float`, optional\n",
    "            FFT integration length (in seconds) for ASD estimation,\n",
    "            default: choose based on sample rate\n",
    "\n",
    "        overlap : `float`, optional\n",
    "            number of seconds of overlap between FFTs, defaults to the\n",
    "            recommended overlap for the given window (if given), or 0\n",
    "\n",
    "        method : `str`, optional\n",
    "            FFT-averaging method (default: ``'median'``)\n",
    "\n",
    "        window : `str`, `numpy.ndarray`, optional\n",
    "            window function to apply to timeseries prior to FFT,\n",
    "            default: ``'hann'``\n",
    "            see :func:`scipy.signal.get_window` for details on acceptable\n",
    "            formats\n",
    "\n",
    "        detrend : `str`, optional\n",
    "            type of detrending to do before FFT (see `~TimeSeries.detrend`\n",
    "            for more details), default: ``'constant'``\n",
    "\n",
    "        asd : `~gwpy.frequencyseries.FrequencySeries`, optional\n",
    "            the amplitude spectral density using which to whiten the data,\n",
    "            overrides other ASD arguments, default: `None`\n",
    "\n",
    "        fduration : `float`, optional\n",
    "            duration (in seconds) of the time-domain FIR whitening filter,\n",
    "            must be no longer than `fftlength`, default: 2 seconds\n",
    "\n",
    "        highpass : `float`, optional\n",
    "            highpass corner frequency (in Hz) of the FIR whitening filter,\n",
    "            default: `None`\n",
    "\n",
    "        **kwargs\n",
    "            other keyword arguments are passed to the `TimeSeries.asd`\n",
    "            method to estimate the amplitude spectral density\n",
    "            `FrequencySeries` of this `TimeSeries`\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        out : `TimeSeries`\n",
    "            a whitened version of the input data with zero mean and unit\n",
    "            variance\n",
    "\n",
    "        See also\n",
    "        --------\n",
    "        TimeSeries.asd\n",
    "            for details on the ASD calculation\n",
    "        TimeSeries.convolve\n",
    "            for details on convolution with the overlap-save method\n",
    "        gwpy.signal.filter_design.fir_from_transfer\n",
    "            for FIR filter design through spectrum truncation\n",
    "\n",
    "        Notes\n",
    "        -----\n",
    "        The accepted ``method`` arguments are:\n",
    "\n",
    "        - ``'bartlett'`` : a mean average of non-overlapping periodograms\n",
    "        - ``'median'`` : a median average of overlapping periodograms\n",
    "        - ``'welch'`` : a mean average of overlapping periodograms\n",
    "\n",
    "        The ``window`` argument is used in ASD estimation, FIR filter design,\n",
    "        and in preventing spectral leakage in the output.\n",
    "\n",
    "        Due to filter settle-in, a segment of length ``0.5*fduration`` will be\n",
    "        corrupted at the beginning and end of the output. See\n",
    "        `~TimeSeries.convolve` for more details.\n",
    "\n",
    "        The input is detrended and the output normalised such that, if the\n",
    "        input is stationary and Gaussian, then the output will have zero mean\n",
    "        and unit variance.\n",
    "\n",
    "        For more on inverse spectrum truncation, see arXiv:gr-qc/0509116.\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298f1403-8797-4eea-9eba-db7f824aa922",
   "metadata": {},
   "source": [
    "> ***–> Skip in this version!***  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2d1afb-3532-4eb9-a95c-ef81fb6a0c71",
   "metadata": {},
   "source": [
    "# 3. Multitaper spectral analysis\n",
    "\n",
    "## 3-1. Multitaper spectrum estimate\n",
    "\n",
    "The multitaper spectrogram code (multitaper_spectrogram_python.py) is ready to use. Check their descriptions about the parameters  \n",
    "> README.md:  \n",
    "* **data**: 1-dimensional time series data  \n",
    "* **Fs**: Frequency at which the data was sampled in Hz  \n",
    "* **frequency_range**: \\[min frequency, max frequency\\] Range of frequencies (Hz) across which to compute the spectrum. The default for all implementations is [0, fs/2].  \n",
    "* **taper_params**: \\[time-halfbandwidth product, number of tapers\\] The time-half bandwidth product (TW) can be computed as N*(BW/2) where N is the length of the window (seconds) and BW is the bandwidth of the main lobe. The bandwidth of the main lobe is also called the frequency resolution because it dictates the minimum difference in frequency that can be detected. \"Number of tapers\" is the number of DPSS tapers to be used to compute the spectrum. The optimal number of tapers is 2*(TW)-1. The default for all implementations is \\[5, 9\\].  \n",
    "* **window_params**: \\[window size (seconds), step size (seconds)\\] These parameters dictate the temporal resolution of the analysis. The multitaper spectrum is computed for a single window of data, then the window moves based on step size and the spectrum will be computed again on the next window until the whole data array has been covered. The default for all implementations is \\[5, 1\\].  \n",
    "* **min_nfft**: Multitaper spectrum computation relies on the Fourier Transform to transform the data from the time domain to the frequency domain. The Fast Fourier Transform (FFT) is an very computationally efficient algorithm to compute the Fourier Transform, and it works most efficiently when the number of data points in the given time series is a power of 2. Therefore, we want to pad the data with 0s to make it reach the closest power of 2. This implementation pads with zeros to the nearest power of 2 automatically, but if a specific power of 2 above the closest power fo 2 is desired, use this parameter. The default for all implementations is 0.  \n",
    "* **weighting**: The DPSS tapers can be weighted differently, and we have included 2 weighting method options - 'eigen' and 'adaptive' - along with the uniformly weighted option 'unity' which is the default for all implementations. Eigenvalue weighting weights the contribution of each taper to the spectrum by it's eigenvalue (frequency concentration). In most cases this makes little difference because most taper's eigenvalues are very close to one anyway. The adaptive weighting method weights the tapers in such a way as to reduce the broadband leakage of non-white ('colored') noise. This method is adapted from pages 368-370 of Percival and Walden's \"Spectral Analysis for Physical Applications: Multitaper and Conventional Univariate Techniques\"5. In practice, the adaptive method does not change the results much at all but is provided here for the sake of completeness.  \n",
    "* **detrend_opt**: Each window of data can be detrended to remove very low frequency oscillation artifacts that can come from a variety of sources. In \"linear\" detrending, a linear model is fit to the window then subtracted out, while in \"constant\" detrending the data is set to be zero mean. The default for all implementations is \"linear\", and the options are \"linear\", \"constant\", and \"off\".  \n",
    "> multitaper_spectrogram_python.py  \n",
    "* Arguments:  \n",
    "data (1d np.array): time series data -- required  \n",
    "fs (float): sampling frequency in Hz  -- required  \n",
    "frequency_range (list): 1x2 list - \\[<min frequency>, <max frequency>\\] (default: \\[0 nyquist\\])  \n",
    "time_bandwidth (float): time-half bandwidth product (window duration\\*half bandwidth of main lobe) (default: 5 Hz\\*s)  \n",
    "num_tapers (int): number of DPSS tapers to use (default: \\[will be computed as floor(2*time_bandwidth - 1)\\])  \n",
    "window_params (list): 1x2 list - \\[window size (seconds), step size (seconds)\\] (default: \\[5 1\\])  \n",
    "detrend_opt (string): detrend data window ('linear' (default), 'constant', 'off') (Default: 'linear')  \n",
    "min_nfft (int): minimum allowable NFFT size, adds zero padding for interpolation (closest 2^x) (default: 0)  \n",
    "multiprocess (bool): Use multiprocessing to compute multitaper spectrogram (default: False)  \n",
    "n_jobs (int): Number of cpus to use if multiprocess = True (default: False). Note: if default is left as None and multiprocess = True, the number of cpus used for multiprocessing will be all available - 1.  \n",
    "weighting (str): weighting of tapers ('unity' (default), 'eigen', 'adapt');  \n",
    "plot_on (bool): plot results (default: True)  \n",
    "return_fig (bool): return plotted spectrogram (default: False)  \n",
    "clim_scale (bool): automatically scale the colormap on the plotted spectrogram (default: True)  \n",
    "verbose (bool): display spectrogram properties (default: True)  \n",
    "xyflip (bool): transpose the mt_spectrogram output (default: False)  \n",
    "ax (axes): a matplotlib axes to plot the spectrogram on (default: None)  \n",
    "* Returns:  \n",
    "mt_spectrogram (TxF np array): spectral power matrix  \n",
    "stimes (1xT np array): timepoints (s) in mt_spectrogram  \n",
    "sfreqs (1xF np array)L frequency values (Hz) in mt_spectrogram  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79febb7-17e1-4521-be49-37c85c312845",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "#Compute the multitaper spectrogram\n",
    "def compute_multipaper_spectogram(ch_idx):\n",
    "    frequency_range = [0, 130] if ch_idx in (0, 1) else [0, 130]  # emg, emg\n",
    "\n",
    "    tempA = mneR_butter.get_data()[ch_idx]\n",
    "    spect, stimes, sfreqs = ms.multitaper_spectrogram(\n",
    "        data=tempA,\n",
    "        fs=SAMPLING_RATE,\n",
    "        frequency_range=frequency_range,\n",
    "        time_bandwidth=5,#Time-half bandwidth (TW): (10 s x 1 Hz)/2 = 5\n",
    "        num_tapers=9,#The number of tapers: 5*2 -1 = 9\n",
    "        #time_bandwidth=2.5,#Time-half bandwidth (TW): (5 s x 1 Hz)/2 = 2.5\n",
    "        #num_tapers=4,#The number of tapers: 2.5*2 -1 = 4\n",
    "        window_params=[3, 1.5],\n",
    "        detrend_opt='linear',\n",
    "        min_nfft=0,\n",
    "        multiprocess=True,\n",
    "        n_jobs=10,\n",
    "        weighting='unity',\n",
    "        plot_on=False,#Customize later\n",
    "        return_fig=False,\n",
    "        clim_scale=True,\n",
    "        verbose=True,\n",
    "        xyflip=False,\n",
    "        ax=None,\n",
    "    )\n",
    "\n",
    "    #Clean the result as a table\n",
    "    tempDF = pd.DataFrame(\n",
    "        spect.T,\n",
    "        index=pd.Index(stimes, name='Time[sec]'),\n",
    "        columns=pd.Index(sfreqs, name='Frequency[Hz]')\n",
    "    )\n",
    "    display(tempDF)\n",
    "    display(tempDF.describe())\n",
    "\n",
    "    psdDF = tempDF\n",
    "\n",
    "    return spect, stimes, sfreqs, psdDF\n",
    "\n",
    "ch_idx = 2\n",
    "spect, stimes, sfreqs, psdDF = compute_multipaper_spectogram(ch_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc2229e-906f-486d-806c-f94e659e40b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "psdDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e701bf-c2f4-47d2-9e5b-6ddc0ddaae4b",
   "metadata": {},
   "source": [
    "## 3-2. Power spectrum density (PSD)\n",
    "### 3-2-1. Spectrogram vizualization at the time–frequcency domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c946e42b-f911-4bb2-91ef-0e19250ba5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def display_spectrogram_dB(spect, title_text=\"\"):\n",
    "    # Visualize the spectrogram (customized from the original multitaper_spectrogram() code)\n",
    "    # # Convert from power to dB\n",
    "    tempA1 = ms.nanpow2db(spect)\n",
    "    # # Set ranges of x-axis and y-axis\n",
    "    tempA2 = stimes / 60  # Convert from sec to min\n",
    "    dx = tempA2[1] - tempA2[0]\n",
    "    dy = sfreqs[1] - sfreqs[0]\n",
    "    extent = [tempA2[0] - dx, tempA2[-1] + dx, sfreqs[-1] + dy, sfreqs[0] - dy]\n",
    "    # # Plot spectrogram\n",
    "    # sns.set(style='ticks', font='Arial', context='notebook')\n",
    "    sns.set(style='ticks', context='notebook')\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(8, 3))\n",
    "    im = ax.imshow(tempA1, extent=extent, aspect='auto')\n",
    "    # im.set_cmap(plt.cm.get_cmap('cet_rainbow4'))#Older matplotlib\n",
    "    im.set_cmap(plt.colormaps.get_cmap('cet_rainbow4'))\n",
    "    clim = np.percentile(tempA1, [5, 98])  # From 5th percentile to 98th\n",
    "    im.set_clim(clim)  # Change colorbar scale\n",
    "    ax.invert_yaxis()\n",
    "    ax.set_xlabel('Time [min]')\n",
    "    ax.set_ylabel('Frequency [Hz]')\n",
    "    # ax.set_title('Subject: '+subject+', Condition: '+condition+', Trial: '+trial+', Channel: '+channel)\n",
    "    ax.set_title(title_text)\n",
    "    fig.colorbar(im, ax=ax, label='PSD [' + r'$\\mathsf{μV^2/Hz}$' + ', dB]')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "title = f\"{FILE_PATH.stem}, Channel: {mneR_butter.ch_names[ch_idx]}\"\n",
    "display_spectrogram_dB(spect, title)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f97f77-52d0-425b-8a22-e5c2bc0e3252",
   "metadata": {},
   "source": [
    "### 3-2-2. Power spectrum visualization at the frequency domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ae94bf-4658-4496-b747-ad17404d883b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_powerSpectrum_dB(psdDFs, subjects, title_text=\"\"):\n",
    "    # Visualize power spectrum density\n",
    "    # # Prepare long-format DF for sns.lineplot(), which calculates the mean\n",
    "    # # with errors automatically during visualization\n",
    "    tempL = []\n",
    "    for psdDF, subject in zip(psdDFs, subjects):\n",
    "        tempDF = ms.nanpow2db(psdDF)  # Convert from power to dB\n",
    "        # tempDF.index = tempDF.index/60#Convert from sec to min\n",
    "        # tempDF.index.name = 'Time[min]'\n",
    "        tempDF = tempDF.reset_index().melt(var_name='Frequency[Hz]', value_name='PSD[dB]', id_vars=['Time[sec]'])\n",
    "        tempDF['Subject'] = subject\n",
    "        tempL.append(tempDF)\n",
    "    tempDF = pd.concat(tempL, axis=0)\n",
    "    # #Plot\n",
    "    # sns.set(style='ticks', font='Arial', context='notebook')\n",
    "    sns.set(style='ticks', context='notebook')\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(4, 3))\n",
    "    sns.lineplot(data=tempDF, x='Frequency[Hz]', y='PSD[dB]',\n",
    "                 hue='Subject', palette='tab10', hue_order=None,\n",
    "                 estimator='mean', ci=95, n_boot=1000, seed=123, sort=True,\n",
    "                 err_style='band', err_kws=None, legend='auto', ax=ax)\n",
    "    sns.despine()\n",
    "    plt.setp(ax, xlim=(tempDF['Frequency[Hz]'].min(), tempDF['Frequency[Hz]'].max()))\n",
    "    # # Log-scale\n",
    "    ax.set_xscale('log', base=10)\n",
    "    ax.minorticks_off()  # Due to ax.set_xscale()\n",
    "    plt.setp(ax, xlim=(1, tempDF['Frequency[Hz]'].max()))  # Due to the excess range by ax.set_xscale()\n",
    "    ax.set_xticks([1, 4, 8, 12, 15, 30, 100])  # delta, theta, alpha, sigma, beta & gamma ranges\n",
    "    ax.get_xaxis().set_major_formatter(matplotlib.ticker.ScalarFormatter())\n",
    "    plt.setp(ax, xlabel='Frequency [Hz] (log-scale)', ylabel='PSD ['+r'$\\mathsf{μV^2/Hz}$'+', dB]\\n(Mean with 95% CI)')\n",
    "    ax.set_title(title_text)\n",
    "    plt.legend(title='Subject', bbox_to_anchor=(1.0, 0.5), loc='center left')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def round_freq_bins(df, step=50.0, agg=\"mean\"):\n",
    "    freqs = df.columns.astype(float)\n",
    "\n",
    "    freq_bins = (freqs // step) * step   # 例: 123 Hz → 100 Hz bin\n",
    "\n",
    "    freq_bins = freq_bins.astype(int).astype(str)\n",
    "\n",
    "    df_out = df.groupby(freq_bins, axis=1).agg(agg)\n",
    "    df_out.columns = df_out.columns.astype(float)  # 再び数値に直す\n",
    "\n",
    "    return df_out\n",
    "\n",
    "\n",
    "# size down if needed\n",
    "_psdDF = round_freq_bins(psdDF, step=2.0, agg=\"mean\")\n",
    "# _psdDF = psdDF\n",
    "\n",
    "display_powerSpectrum_dB([_psdDF], [mneR_butter.ch_names[ch_idx]], title)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad83298-d3e4-4fab-bd37-6f2b99d80cfe",
   "metadata": {},
   "source": [
    "## 3-3. Power spectrum (PS)\n",
    "> According to Dr. Takeuchi's \"whitening\" processing, not power spectrum density (PSD, uV^2 / Hz) but power spectrum (PS, uV^2) is used as the final presentation. Also, no dB conversion is needed.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6c245f-122a-4c00-955a-aea3673fff0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tempDF = psdDF.copy()\n",
    "\n",
    "# Convert from PSD to PS\n",
    "for col_n in tempDF.columns:\n",
    "    tempDF[col_n] = tempDF[col_n] * col_n\n",
    "\n",
    "display(tempDF)\n",
    "display(tempDF.describe())\n",
    "\n",
    "psDF = tempDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f088ae9b-8280-4d89-9fec-5bae6bb9d552",
   "metadata": {},
   "source": [
    "### 3-3-1. Spectrogram vizualization at the time–frequcency domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dca57ab-3d10-4463-bee0-6d9045e54b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_spectrogram_uv2(psDF, title_text=\"\"):\n",
    "    # Visualize the spectrogram\n",
    "    # (customized from the original multitaper_spectrogram() code)\n",
    "    # # Convert from power to dB\n",
    "    # # -> No need this time\n",
    "    tempA1 = psDF.to_numpy().T\n",
    "    # # Set ranges of x-axis and y-axis\n",
    "    tempA2 = stimes / 60  # Convert from sec to min\n",
    "    dx = tempA2[1] - tempA2[0]\n",
    "    dy = sfreqs[1] - sfreqs[0]\n",
    "    extent = [tempA2[0] - dx, tempA2[-1] + dx, sfreqs[-1] + dy, sfreqs[0] - dy]\n",
    "    # # Plot spectrogram\n",
    "    # sns.set(style='ticks', font='Arial', context='notebook')\n",
    "    sns.set(style='ticks', context='notebook')\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(8, 3))\n",
    "    im = ax.imshow(tempA1, extent=extent, aspect='auto')\n",
    "    # im.set_cmap(plt.cm.get_cmap('cet_rainbow4'))#Older matplotlib\n",
    "    im.set_cmap(plt.colormaps.get_cmap('cet_rainbow4'))\n",
    "    clim = np.percentile(tempA1, [5, 98])  # From 5th percentile to 98th\n",
    "    im.set_clim(clim)  # Change colorbar scale\n",
    "    ax.invert_yaxis()\n",
    "    ax.set_xlabel('Time [min]')\n",
    "    ax.set_ylabel('Frequency [Hz]')\n",
    "    ax.set_title(title_text)\n",
    "    fig.colorbar(im, ax=ax, label='Power [' + r'$\\mathsf{μV^2}$' + ']')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "display_spectrogram_uv2(psDF, title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a72e59c-e185-41bd-9d6c-91deafde6b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize both waveform and spectrogram\n",
    "def display_waveforms_and_spectrogram(ch_idx, psDF, title_text=\"\"):\n",
    "    # sns.set(style='ticks', font='Arial', context='notebook')\n",
    "    sns.set(style='ticks', context='notebook')\n",
    "    fig, axes = plt.subplots(\n",
    "        nrows=2, ncols=1, figsize=(7.5, 6.5), sharex=True, sharey=False,\n",
    "        gridspec_kw={'height_ratios': [1, 1], 'hspace': 0.1}\n",
    "    )\n",
    "    for ax_i, ax in enumerate(axes.flat):\n",
    "        # sns.despine() seems to override the below bottom spine setting\n",
    "        ax.spines.top.set_visible(False)\n",
    "        # sns.despine() seems to override the below bottom spine setting\n",
    "        ax.spines.right.set_visible(False)\n",
    "        if ax_i == 0:\n",
    "            # Visualize LFP waveform trace (full range)\n",
    "            # # Convert from sec to min for x-axis\n",
    "            data = mneR_butter.get_data()\n",
    "            times = mneR_butter.times.copy() / 60\n",
    "            # # Plot\n",
    "            ax.plot(times, data[ch_idx], color='k', linewidth=0.1)\n",
    "            plt.setp(axes, xlim=(times.min(), times.max()))  # Set across panels\n",
    "            ax.yaxis.set_major_formatter(\n",
    "                matplotlib.ticker.StrMethodFormatter('{x:,.0f}')\n",
    "            )\n",
    "            # # Set axis\n",
    "            plt.setp(ax.get_xticklabels(), visible=False)\n",
    "            plt.setp(ax, xlabel='', ylabel='LFP [μV]')\n",
    "            ax.set_title(title_text)  # Overall title\n",
    "        else:\n",
    "            # Visualize the spectrogram\n",
    "            # (customized from the original multitaper_spectrogram() code)\n",
    "            # # Convert from power to dB\n",
    "            # # -> No need this time\n",
    "            tempA1 = psDF.to_numpy().T\n",
    "            # # Set ranges of x-axis and y-axis\n",
    "            tempA2 = stimes / 60  # Convert from sec to min\n",
    "            dx = tempA2[1] - tempA2[0]\n",
    "            dy = sfreqs[1] - sfreqs[0]\n",
    "            extent = [\n",
    "                tempA2[0] - dx, tempA2[-1] + dx,\n",
    "                sfreqs[-1] + dy, sfreqs[0] - dy\n",
    "            ]\n",
    "            # # Plot spectrogram\n",
    "            im = ax.imshow(tempA1, extent=extent, aspect='auto')\n",
    "            # im.set_cmap(plt.cm.get_cmap('cet_rainbow4'))#Older matplotlib\n",
    "            im.set_cmap(plt.colormaps.get_cmap('cet_rainbow4'))\n",
    "            clim = np.percentile(tempA1, [5, 98])  # From 5th percentile to 98th\n",
    "            im.set_clim(clim)  # Change colorbar scale\n",
    "            ax.invert_yaxis()\n",
    "            # # Log-scale\n",
    "            ax.set_yscale('log', base=10)\n",
    "            ax.minorticks_off()  # Due to ax.set_yscale()\n",
    "            plt.setp(ax, ylim=(1, sfreqs[-1] + dy))  # Due to the excess range by ax.set_yscale()\n",
    "            ax.set_yticks([1, 4, 8, 12, 15, 30, 100])  # delta, theta, alpha, sigma, beta & gamma ranges\n",
    "            ax.get_yaxis().set_major_formatter(matplotlib.ticker.ScalarFormatter())\n",
    "            plt.setp(ax, xlabel='Time [min]', ylabel='Frequency [Hz] (log-scale)')\n",
    "            # fig.colorbar(\n",
    "            #     im, ax=axes, label='PSD [' + r'$\\mathsf{μV^2/Hz}$' + ', dB]',\n",
    "            #     location='bottom', orientation='horizontal', shrink=0.5, anchor=(1.0, 1.0)\n",
    "            # )\n",
    "            # #Make a colorbar manually to set title position\n",
    "            cax = fig.add_axes([0.5, -0.025, 0.4, 0.03])  # Manual adjustment\n",
    "            plt.colorbar(im, cax=cax, orientation='horizontal')\n",
    "            cax.set_ylabel(\n",
    "                'Power [' + r'$\\mathsf{μV^2}$' + ']',\n",
    "                rotation=0, horizontalalignment='right',\n",
    "                verticalalignment='center', rotation_mode='anchor'\n",
    "            )\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "display_waveforms_and_spectrogram(ch_idx, psDF, title)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b668bebf-e7aa-4a77-b82e-09d393bbae42",
   "metadata": {},
   "source": [
    "### 3-2-2. Power spectrum visualization at the frequency domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a2696d-5d92-4b6c-8840-19fc8f181465",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_powerSpectrum_uv2(psDFs, subjects, title_text=\"\"):\n",
    "    # Visualize power spectrum density\n",
    "    # # Prepare long-format DF for sns.lineplot(),\n",
    "    # # which calculates the mean with errors automatically during visualization\n",
    "    tempL = []\n",
    "    for psDF, subject in zip(psDFs, subjects):\n",
    "        tempDF = psDF  # Convert from power to dB -> No need this time\n",
    "        # tempDF.index = tempDF.index/60#Convert from sec to min\n",
    "        # tempDF.index.name = 'Time[min]'\n",
    "        tempDF = tempDF.reset_index()\n",
    "        tempDF = tempDF.melt(\n",
    "            var_name='Frequency[Hz]',\n",
    "            value_name='Power[uV^2]',\n",
    "            id_vars=['Time[sec]']\n",
    "        )\n",
    "        tempDF['Subject'] = subject\n",
    "        tempL.append(tempDF)\n",
    "    tempDF = pd.concat(tempL, axis=0)\n",
    "    # # Plot\n",
    "    # sns.set(style='ticks', font='Arial', context='notebook')\n",
    "    sns.set(style='ticks', context='notebook')\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(4, 3))\n",
    "    sns.lineplot(data=tempDF, x='Frequency[Hz]', y='Power[uV^2]',\n",
    "                 hue='Subject', palette='tab10', hue_order=None,\n",
    "                 estimator='mean', ci=95, n_boot=1000, seed=123, sort=True,\n",
    "                 err_style='band', err_kws=None, legend='auto', ax=ax)\n",
    "    sns.despine()\n",
    "    plt.setp(ax, xlim=(tempDF['Frequency[Hz]'].min(), tempDF['Frequency[Hz]'].max()))\n",
    "    # # Log-scale\n",
    "    ax.set_xscale('log', base=10)\n",
    "    ax.minorticks_off()  # Due to ax.set_xscale()\n",
    "    plt.setp(ax, xlim=(1, tempDF['Frequency[Hz]'].max()))  # Due to the excess range by ax.set_xscale()\n",
    "    ax.set_xticks([1, 4, 8, 12, 15, 30, 100])  # delta, theta, alpha, sigma, beta & gamma ranges\n",
    "    ax.get_xaxis().set_major_formatter(matplotlib.ticker.ScalarFormatter())\n",
    "    ax.set_yscale('log', base=10)\n",
    "    ax.axvline(x=50, **{'linestyle': '--', 'color': 'k'})\n",
    "    # plt.setp(ax, ylim=(50, 500000))#To fix the range among the channels/samples\n",
    "    plt.setp(\n",
    "        ax,\n",
    "        xlabel='Frequency [Hz] (log-scale)',\n",
    "        ylabel='Power [' + r'$\\mathsf{μV^2}$' + ']\\n(Mean with 95% CI)'\n",
    "    )\n",
    "    ax.set_title(title_text)\n",
    "    plt.legend(title='Subject', bbox_to_anchor=(1.0, 0.5), loc='center left')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# size down if needed\n",
    "_psDF = round_freq_bins(psDF, step=2.0, agg=\"mean\")\n",
    "# _psdDF = psdDF\n",
    "\n",
    "display_powerSpectrum_uv2([_psDF], [mneR_butter.ch_names[ch_idx]], title)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5a54c3-b7b4-4df1-aca1-2aabbb1c2603",
   "metadata": {},
   "source": [
    "## Cf. 1. Different channel 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17641b84-5122-43b4-8c1b-497c63964940",
   "metadata": {},
   "outputs": [],
   "source": [
    "ch_idx = 2\n",
    "spect, stimes, sfreqs, psdDF = compute_multipaper_spectogram(ch_idx)\n",
    "title = f\"{FILE_PATH.stem}, Channel: {mneR_butter.ch_names[ch_idx]}\"\n",
    "display_spectrogram_dB(spect, title)\n",
    "display_powerSpectrum_dB([psdDF], [mneR_butter.ch_names[ch_idx]], title)\n",
    "\n",
    "tempDF = psdDF.copy()\n",
    "\n",
    "# Convert from PSD to PS\n",
    "for col_n in tempDF.columns:\n",
    "    tempDF[col_n] = tempDF[col_n] * col_n\n",
    "\n",
    "display(tempDF)\n",
    "display(tempDF.describe())\n",
    "\n",
    "psDF = tempDF\n",
    "display_spectrogram_uv2(psDF, title)\n",
    "display_waveforms_and_spectrogram(ch_idx, psDF, title)\n",
    "display_powerSpectrum_uv2([psDF], [mneR_butter.ch_names[ch_idx]], title)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c434441-38e0-449b-a4c2-97bcdf6b27ef",
   "metadata": {},
   "source": [
    "## Cf. 2. Different channel 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ec622f-419e-4a2d-a7b4-2fed970f3503",
   "metadata": {},
   "outputs": [],
   "source": [
    "ch_idx = 2\n",
    "spect, stimes, sfreqs, psdDF = compute_multipaper_spectogram(ch_idx)\n",
    "title = f\"{FILE_PATH.stem}, Channel: {mneR_butter.ch_names[ch_idx]}\"\n",
    "display_spectrogram_dB(spect, title)\n",
    "display_powerSpectrum_dB([psdDF], [mneR_butter.ch_names[ch_idx]], title)\n",
    "\n",
    "tempDF = psdDF.copy()\n",
    "\n",
    "# Convert from PSD to PS\n",
    "for col_n in tempDF.columns:\n",
    "    tempDF[col_n] = tempDF[col_n] * col_n\n",
    "\n",
    "display(tempDF)\n",
    "display(tempDF.describe())\n",
    "\n",
    "psDF = tempDF\n",
    "display_spectrogram_uv2(psDF, title)\n",
    "display_waveforms_and_spectrogram(ch_idx, psDF, title)\n",
    "display_powerSpectrum_uv2([psDF], [mneR_butter.ch_names[ch_idx]], title)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124120ac-03c5-44ab-9daf-676fd41ade6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sfreqs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3644e108-ccde-4b6f-9d7a-bdc013b41ca0",
   "metadata": {},
   "source": [
    "# 4. SleepEns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f61d447-9b3c-4875-b31b-b132f97dbc6f",
   "metadata": {},
   "source": [
    "## 4-1. Run Sleep Ensemble\n",
    "reference: [https://github.com/paradoxysm/sleepens/blob/master/sleepens/main.py](https://github.com/paradoxysm/sleepens/blob/master/sleepens/main.py)\n",
    "\n",
    "We run SleepENS on Python 3.7 with pinned dependencies, using the system Python and a virtual environment (venv).  \n",
    "Outputs are written to `$DATA_FOLDER/sleepEnsOutput/`, and scripts are located in `./python/sleepens/`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbab9958-a697-4b77-b071-9720c04dffc7",
   "metadata": {},
   "source": [
    "## 4-2. check result\n",
    "'SCORE_MAP': { 'AW': 0, 'QW': 1, 'NR': 2, 'R': 3 },"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0c94f1-6c3c-4f4b-88a1-7f3956a1f1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to develop faster, use small file.\n",
    "    # Path(DATA_FOLDER, \"mneRaw\", \"20250917-001-0.fif\")\n",
    "file_name = \"20250917-001-0{}.fif\"\n",
    "\n",
    "mneR_ens = mne.io.read_raw_fif(\n",
    "    Path(DATA_FOLDER, \"sleepEnsOutput\", file_name.format(\"-predictions\"))\n",
    ")\n",
    "mneI_ens = mneR_ens.info.copy()\n",
    "display(mneR_ens)\n",
    "display(mneR_ens.annotations)\n",
    "print(mneR_ens.ch_names)\n",
    "print(\"=\" * 30)\n",
    "\n",
    "mneR_orig = mne.io.read_raw_fif(\n",
    "    Path(DATA_FOLDER, \"mneRaw_band_notch\", file_name.format(\"\"))\n",
    ")\n",
    "display(mneR_orig)\n",
    "print(mneR_orig.ch_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f68e37-2b5f-4b14-a112-69bb2eb1b702",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Hard-coded state mapping\n",
    "SCORE_MAP = {'AW': 0, 'QW': 1, 'NREM': 2, 'REM': 3}\n",
    "INV_SCORE_MAP = {v: k for k, v in SCORE_MAP.items()}\n",
    "_STATE_COLORS = {\n",
    "    0: (162, 53, 47),   # AW\n",
    "    1: (236, 197, 72),  # QW\n",
    "    2: (81, 158, 89),   # NREM\n",
    "    3: (52, 71, 113),   # REM\n",
    "}\n",
    "\n",
    "# Normalize to 0–1 for Matplotlib\n",
    "STATE_COLORS = {k: tuple(np.array(v, dtype=float) / 255.0) for k, v in _STATE_COLORS.items()}\n",
    "\n",
    "\n",
    "def display_waveforms_with_states_simple(\n",
    "    raw: mne.io.Raw,\n",
    "    labels_raw: mne.io.Raw,     # 1-channel Raw; integer labels 0..3 per sample\n",
    "    title_text: str = \"\",\n",
    "    span: tuple = (0, -1),      # (start, end) in sec or min\n",
    "    unit: str = \"sec\",          # \"sec\", \"min\", or \"time\"  ← \"time\" 追加\n",
    "    alpha_band: float = 0.15\n",
    "):\n",
    "    \"\"\"\n",
    "    Plot multi-channel waveforms and overlay 4-state categorical bands.\n",
    "    Labels are provided as a 1-channel mne.io.Raw, with integer states:\n",
    "      0=AW, 1=QW, 2=NR, 3=R.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    raw : mne.io.Raw\n",
    "        Source time-series to plot.\n",
    "    labels_raw : mne.io.Raw\n",
    "        1-channel Raw containing per-sample integer labels (0..3).\n",
    "        If sfreq differs from `raw`, it will be resampled to match.\n",
    "    title_text : str\n",
    "        Title for the figure.\n",
    "    span : tuple\n",
    "        Time range to plot (start, end) interpreted in seconds or minutes.\n",
    "        Use -1 or None for end to indicate the end of recording.\n",
    "    unit : {\"sec\",\"min\",\"time\"}\n",
    "        Unit for `span`. \"time\" は表示のみ HH:MM:SS（解釈は秒）。\n",
    "    alpha_band : float\n",
    "        Alpha value for the background state bands.\n",
    "    \"\"\"\n",
    "    # ---- Validate inputs ----\n",
    "    if unit not in {\"sec\", \"min\", \"time\"}:  # CHANGED\n",
    "        raise ValueError(\"unit must be 'sec' or 'min' or 'time'\")  # CHANGED\n",
    "    if labels_raw.info[\"nchan\"] != 1:\n",
    "        raise ValueError(\"labels_raw must have exactly 1 channel (integer labels 0..3).\")\n",
    "\n",
    "    # ---- Match sampling frequency ----\n",
    "    sfreq = raw.info[\"sfreq\"]\n",
    "    labs = labels_raw.copy()\n",
    "    if not np.isclose(labs.info[\"sfreq\"], sfreq):\n",
    "        labs.resample(sfreq, npad=\"auto\")\n",
    "\n",
    "    # ---- Extract and sanitize label vector ----\n",
    "    lab = labs.get_data()[0]              # shape (n_times_labels,)\n",
    "    # Round to nearest integer, clip to 0..3\n",
    "    lab = np.rint(lab).astype(int)\n",
    "    lab = np.clip(lab, 0, 3)\n",
    "\n",
    "    # Align label length to raw length (nearest-neighbor if different)\n",
    "    if lab.shape[0] != raw.n_times:\n",
    "        idx = np.linspace(0, lab.shape[0] - 1, raw.n_times)\n",
    "        lab = lab[np.rint(idx).astype(int)]\n",
    "\n",
    "    # ---- Determine plotting window in seconds ----\n",
    "    start, end = span\n",
    "    if unit == \"min\":\n",
    "        start = None if start is None else float(start) * 60.0\n",
    "        end   = None if end   is None else float(end)   * 60.0\n",
    "    else:  # \"sec\" or \"time\"  # CHANGED\n",
    "        start = None if start is None else float(start)\n",
    "        end   = None if end   is None else float(end)\n",
    "\n",
    "    if end in (-1, None):\n",
    "        end = raw.times[-1]\n",
    "    start = max(start if start is not None else raw.times[0], raw.times[0])\n",
    "    end   = min(end, raw.times[-1])\n",
    "\n",
    "    s_idx, e_idx = raw.time_as_index([start, end])\n",
    "    data  = raw.get_data()[:, s_idx:e_idx]\n",
    "    times = raw.times[s_idx:e_idx]\n",
    "    labs_win = lab[s_idx:e_idx]\n",
    "\n",
    "    # ---- Find contiguous segments of same label ----\n",
    "    def contiguous_segments(lbl: np.ndarray):\n",
    "        if lbl.size == 0:\n",
    "            return []\n",
    "        edges = np.where(np.diff(lbl) != 0)[0] + 1\n",
    "        idxs = np.r_[0, edges, lbl.size]\n",
    "        return [(idxs[i], idxs[i+1], int(lbl[idxs[i]])) for i in range(len(idxs)-1)]\n",
    "\n",
    "    segs = contiguous_segments(labs_win)\n",
    "\n",
    "    # ---- Create figure ----\n",
    "    n_ch = raw.info[\"nchan\"]\n",
    "    fig_h = max(1.6, n_ch / 1.5)\n",
    "    fig, axes = plt.subplots(\n",
    "        nrows=n_ch, ncols=1,\n",
    "        figsize=(8.5, fig_h),\n",
    "        sharex=True, sharey=True,\n",
    "        gridspec_kw={'height_ratios': [1]*n_ch, 'hspace': 0.0}\n",
    "    )\n",
    "    if n_ch == 1:\n",
    "        axes = [axes]\n",
    "\n",
    "    # NEW: unit==\"time\" なら HH:MM:SS フォーマッタ（表示のみ変更）\n",
    "    if unit == \"time\":  # NEW\n",
    "        def _sec_to_hhmmss(x, pos):  # x は秒（float）\n",
    "            s = int(max(0, round(x)))\n",
    "            h = s // 3600\n",
    "            m = (s % 3600) // 60\n",
    "            ss = s % 60\n",
    "            return f\"{h:02d}:{m:02d}:{ss:02d}\"\n",
    "        for ax in axes:\n",
    "            ax.xaxis.set_major_formatter(FuncFormatter(_sec_to_hhmmss))\n",
    "\n",
    "    # Axis limits\n",
    "    if times.size == 0 or data.size == 0:\n",
    "        xlim = (0, 0); ylim = (-1, 1)\n",
    "    else:\n",
    "        xlim = (times[0], times[-1])\n",
    "        dmin, dmax = float(np.nanmin(data)), float(np.nanmax(data))\n",
    "        if dmin == dmax:\n",
    "            dmin, dmax = dmin - 1.0, dmax + 1.0\n",
    "        ylim = (dmin, dmax)\n",
    "    for ax in axes:\n",
    "        ax.set_xlim(*xlim)\n",
    "        ax.set_ylim(*ylim)\n",
    "\n",
    "    # ---- Draw channels with background state bands ----\n",
    "    for i, ax in enumerate(axes):\n",
    "        # Background bands per contiguous state\n",
    "        for s, e, lab_val in segs:\n",
    "            x0 = times[s]\n",
    "            x1 = times[e-1] if e-1 < times.size else times[-1]\n",
    "            ax.axvspan(x0, x1, color=STATE_COLORS[lab_val], alpha=alpha_band)\n",
    "\n",
    "        # Waveform trace\n",
    "        ax.plot(times, data[i], linewidth=0.35, color='k')\n",
    "\n",
    "        # Cosmetics\n",
    "        ax.spines.top.set_visible(False)\n",
    "        ax.spines.right.set_visible(False)\n",
    "        ax.set_yticks([])\n",
    "        ax.set_ylabel(\n",
    "            raw.ch_names[i],\n",
    "            rotation=0, ha='right', va='center',\n",
    "            rotation_mode='anchor'\n",
    "        )\n",
    "        if i == 0 and title_text:\n",
    "            ax.set_title(title_text)\n",
    "        if i == n_ch - 1:\n",
    "            if unit == \"time\":                      # NEW\n",
    "                ax.set_xlabel(\"Time [HH:MM:SS]\")    # NEW\n",
    "            else:\n",
    "                ax.set_xlabel(\"Time [sec]\")\n",
    "        else:\n",
    "            ax.spines.bottom.set_visible(False)\n",
    "            ax.get_xaxis().set_visible(False)\n",
    "\n",
    "    # Legend\n",
    "    handles = [Patch(color=STATE_COLORS[k], alpha=alpha_band, label=INV_SCORE_MAP[k]) for k in range(4)]\n",
    "    plt.subplots_adjust(right=0.80)\n",
    "    axes[0].legend(\n",
    "        handles=handles,\n",
    "        loc=\"upper left\",\n",
    "        bbox_to_anchor=(1.02, 1.0),  # 右外\n",
    "        borderaxespad=0.0,\n",
    "        frameon=False,\n",
    "        title=\"State\"\n",
    "    )\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ca56ea-656b-4e9d-a897-b068123dccd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_waveforms(mneR_ens, unit=\"min\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01da0169-934a-4a73-a429-7e4b5f43a90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_waveforms(mneR_ens,span=(60 * 60, 60 * 80),unit=\"sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99d6155-4f54-48a8-9666-6b4610d10ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = mneR_ens.copy().pick(\"state\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773128b9-8ece-4320-892e-ab6ea318fa94",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_waveforms_with_states_simple(\n",
    "    mneR_orig,\n",
    "    state,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091bce31-d38e-40e7-a132-ac62591e5775",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_waveforms_with_states_simple(\n",
    "    mneR_orig,\n",
    "    state,\n",
    "    span=(6300, 6400),\n",
    "    unit=\"time\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e363fec-e3b7-4c96-924c-3aafa78350e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_waveforms_with_states_simple(\n",
    "    mneR_orig,\n",
    "    state,\n",
    "    span=(6000, 6400)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb4824e-a83d-41e3-b5f2-470b07dfbc31",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_waveforms_with_states_simple(\n",
    "    mneR_orig,\n",
    "    state,\n",
    "    span=(6100, 6200),\n",
    "    unit=\"time\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e10c039-87df-415e-a352-baa444de7829",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_waveforms_with_states_simple(\n",
    "    mneR_orig,\n",
    "    state,\n",
    "    span=(1990, 2500),\n",
    "    unit=\"time\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525cc781-92a9-4645-ad3f-9823a0c6a2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_waveforms_with_states_simple(\n",
    "    mneR_orig,\n",
    "    state,\n",
    "    span=(1990, 2500),\n",
    "    unit=\"time\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae19e497-3ef2-403a-883f-395baec95b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_waveforms_with_states_simple(\n",
    "    mneR_orig,\n",
    "    state,\n",
    "    span=(2330, 2400),\n",
    "    unit=\"time\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03cd36c-f1a5-4649-bb3b-f25764f433bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_waveforms_with_states_simple(\n",
    "    mneR_orig,\n",
    "    state,\n",
    "    span=(450, 600),\n",
    "    unit=\"time\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83703b6c-b018-4cef-b6af-d6d92e7e7d28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7a7ba8-2d31-4fab-ad21-23c6f164f30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "time = 6300\n",
    "sec_to_time(time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac8f886-cd6b-47fe-b21c-c05fdbd8e294",
   "metadata": {},
   "source": [
    "# 5. Check mp4\n",
    "## 5-1. load .tsp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac333867-93ac-4847-87a1-06b5dc65ed2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "filepath = DATA_FOLDER / \"20250917-001.tsp\"\n",
    "timestamps = np.loadtxt(filepath, dtype=np.float64)\n",
    "\n",
    "# TimeStamp of the end of recording (computer clock - ms) = 541695087\n",
    "# TimeStamp of the start of recording (computer clock - ms) = 514427685\n",
    "start_ms = 514427685\n",
    "df = pd.DataFrame({\"timestamp_ms\": timestamps})\n",
    "df[\"elapsed_sec\"] = (df[\"timestamp_ms\"] - start_ms) / 1000.0\n",
    "df[\"elapsed_time\"] = pd.to_timedelta(df[\"elapsed_sec\"], unit=\"s\").astype(str)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d9cd7b-5e60-4386-b9eb-0aac93604cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f543f360-1350-497b-b3d1-02d58430b47d",
   "metadata": {},
   "source": [
    "The time 07:34:27.005000 differs from the time confirmed in the video viewer.\n",
    "This is almost certainly due to the video not being at 30fps.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a767089d-302f-4ebb-aafc-7648bb7387da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add elapsed_time_30fps column\n",
    "fps = 30.0\n",
    "df[\"elapsed_sec_30fps\"] = df.index / fps\n",
    "df[\"elapsed_time_30fps\"] = pd.to_timedelta(df[\"elapsed_sec_30fps\"], unit=\"s\").astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8958b1-2cc5-422b-9b6b-a175d5707b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082d1c7e-69f0-4528-8149-b14ed3d98c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_misinterpreted_time(df: pd.DataFrame, *time_sec: int):\n",
    "    for t in time_sec:\n",
    "        idx = (df[\"elapsed_sec\"] - t).abs().idxmin()\n",
    "        res = df.loc[idx, \"elapsed_time_30fps\"]\n",
    "        print(t, \":\", res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2c7910-0c93-4b0d-912a-81a8ee08226c",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_misinterpreted_time(df, *[6000 + i * 10 for i in range(50)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9feaabc3-dae8-4eab-b606-81ea2fdecb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_misinterpreted_time(df, *[2000 + i * 10 for i in range(50)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46776302-1108-4e3d-a47e-d01f25328a66",
   "metadata": {},
   "source": [
    "## 5-2. mp4 to mkv\n",
    "mp4 is not able to contain .tsp data.So, convert to mkv and load .tsp to fix time stamp.\n",
    "this part is done on shell, save script here.\n",
    "\n",
    "this script had run on `sleepStateExperiment_from_video`\n",
    "\n",
    "```.sh\n",
    "mkdir -p ./out_mkv\n",
    "for f in ./out/*.mp4; do\n",
    "    base=$(basename \"$f\" .mp4)\n",
    "    ffmpeg -i \"$f\" -c copy \"./out_mkv/${base}.mkv\"\n",
    "done\n",
    "\n",
    "mkdir -p ./out_mkv_corrected\n",
    "```\n",
    "and \n",
    "`sleepStateExperiment_from_video/correct_mkv.sh`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec19316-341a-48bf-a243-743d4f02968a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4f150a61-d6c9-4c9c-ac04-dcd645a58e97",
   "metadata": {},
   "source": [
    "# 6. Run at all EEG channel\n",
    "## 6-1. create mne.io.Raw object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ba5172-5293-4d49-8e4e-9806c2a4e609",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_meta(path):\n",
    "    meta = {}\n",
    "    with open(path, encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            splitter = \" = \"\n",
    "            if not line or splitter not in line:\n",
    "                continue\n",
    "            key, value = map(str.strip, line.split(splitter, 1))\n",
    "            try:\n",
    "                value = float(value)\n",
    "            except ValueError:\n",
    "                value = value\n",
    "            meta[key] = value\n",
    "    return meta\n",
    "\n",
    "\n",
    "def load_data(dat_path, eeg_ch_idx):\n",
    "    n_channels = 12\n",
    "    dtype = np.dtype('<i2')  # Little Endian の uint16。合わなければ <i2 に切替\n",
    "\n",
    "    array = np.fromfile(dat_path, dtype=dtype)\n",
    "    if array.size % n_channels != 0:\n",
    "        raise Exception(\"Warning: can't divede with N_CHANNELS\")\n",
    "\n",
    "    n_frames = array.size // n_channels\n",
    "    data = array.reshape(n_frames, n_channels)\n",
    "\n",
    "    # delete unused channels\n",
    "    data = data[:, [0, 1, eeg_ch_idx]]\n",
    "    n_channels = 3\n",
    "\n",
    "    return data, n_channels\n",
    "\n",
    "\n",
    "def convert_to_Volt(data):\n",
    "    # data is to large to run following,\n",
    "    # data = data.astype(np.float16)/(1 << 15) * 5\n",
    "    # hence, use chunk\n",
    "    chunk = 50_000_000\n",
    "    scale = np.float16(1 << 15)\n",
    "    data_v = np.empty_like(data, dtype=np.float16)\n",
    "    for start in range(0, data.size, chunk):\n",
    "        end = min(start + chunk, data.size)\n",
    "        tmp_data = data[start:end].astype(np.float16)\n",
    "        tmp_data = tmp_data / scale * 5 / (10 ** 3)\n",
    "        data_v[start:end] = tmp_data\n",
    "\n",
    "    return data_v\n",
    "\n",
    "\n",
    "\n",
    "def rows_for_2gb_segment(\n",
    "    n_ch: int,\n",
    "    sampling_rate: int,\n",
    "    write_dtype: np.dtype = np.dtype(np.float32),\n",
    "    target_bytes: int = 2 * 1024**3,\n",
    "    header_margin: int = 16 * 1024**2,\n",
    "    round_sec: int = 5,\n",
    ") -> int:\n",
    "\n",
    "    # bytes per round_sec\n",
    "    dtype_size = write_dtype.itemsize\n",
    "    bytes_per_row = n_ch * dtype_size\n",
    "    bytes_per_round_sec = bytes_per_row * int(sampling_rate * round_sec)\n",
    "\n",
    "    # effective size budget (avoid header/metadata overhead)\n",
    "    effective_max = target_bytes - header_margin\n",
    "\n",
    "    # max rows that fit in the budget\n",
    "    max_round_sec = effective_max // bytes_per_round_sec\n",
    "    max_rows = max_round_sec * int(sampling_rate * round_sec)\n",
    "\n",
    "    return max_rows\n",
    "\n",
    "\n",
    "def create_and_save_mneRaw(data, save_path, seg_len):\n",
    "    # Transpose the table\n",
    "    tempA = data.transpose()\n",
    "    n_t = tempA.shape[1]\n",
    "    saved_paths = []\n",
    "    for part, start in enumerate(range(0, n_t, seg_len)):\n",
    "        end = min(start + seg_len, n_t)\n",
    "\n",
    "        seg = np.ascontiguousarray(tempA[:, start:end], dtype=np.float32)\n",
    "\n",
    "        raw = mne.io.RawArray(seg, mneInfo, first_samp=start)\n",
    "\n",
    "        f_path = Path(f\"{save_path}-{part}.fif\")\n",
    "        raw.save(f_path, overwrite=True, fmt=\"single\")\n",
    "        print(f\"Saved {f_path}  |  samples={seg.shape[1]}  seconds≈{seg.shape[1]/SAMPLING_RATE:.1f}\")\n",
    "\n",
    "        saved_paths.append(f_path)\n",
    "\n",
    "        del raw, seg\n",
    "        gc.collect()\n",
    "    return saved_paths\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfae6108-c819-42f5-8fec-8a889db7273a",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = Path(\"/home/data/sleepStateExperiment_from_video/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d06237-0521-4e4b-9f60-418aa9ca8c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_path = DATA_FOLDER / \"20250917-001.meta\"\n",
    "# load meta\n",
    "meta = load_meta(meta_path)\n",
    "START_TS = meta[\"TimeStamp of the start of recording (computer clock - ms)\"]\n",
    "END_TS = meta[\"TimeStamp of the end of recording (computer clock - ms)\"]\n",
    "SAMPLING_RATE = int(meta[\"Sampling rate\"])\n",
    "FILE_PATH = Path(meta[\"Filename\"])\n",
    "\n",
    "# load data\n",
    "# we use\n",
    "# ch-1, 2 as 2 EMG channel\n",
    "# ch 3-8 as EEG channel\n",
    "\n",
    "EEG_CH_NAMES = [\n",
    "    \"Skull-1\", \"Skull-2\",\n",
    "    \"HPC-1\", \"HPC-2\",\n",
    "    \"S1-1\", \"S1-2\"\n",
    "]\n",
    "EEG_CH_IDX = list(range(2, 8))\n",
    "dat_path = Path(DATA_FOLDER, FILE_PATH.name)\n",
    "for ch_idx, ch_name in zip(EEG_CH_IDX, EEG_CH_NAMES):\n",
    "\n",
    "    data, N_CHANNELS = load_data(dat_path, ch_idx)\n",
    "\n",
    "    # convert to Volt\n",
    "    data_v = convert_to_Volt(data)\n",
    "\n",
    "    # create an mne object\n",
    "    CHANNEL_NAMES = [\"EMG-1\", \"EMG-2\", ch_name]\n",
    "    CHANNEL_TYPES = [\"emg\"] * 2 + [\"eeg\"] * 1\n",
    "    MNE_DIR = Path(DATA_FOLDER, \"mneRaw\")\n",
    "    # create an mne.Info object\n",
    "    mneInfo = mne.create_info(CHANNEL_NAMES, SAMPLING_RATE, ch_types=CHANNEL_TYPES)\n",
    "\n",
    "    # create an mne.io.Raw object\n",
    "    save_path = Path(DATA_FOLDER, \"analysis_tmp\", FILE_PATH.stem + ch_name)\n",
    "    seg_len = rows_for_2gb_segment(N_CHANNELS, SAMPLING_RATE)\n",
    "    create_and_save_mneRaw(data_v, save_path, seg_len)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d67b4422-8735-4000-b1b7-cdb18a0595a8",
   "metadata": {},
   "source": [
    "## 6-2. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b094cfc-cb6c-4850-b1ea-e479f3af45c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = Path(\"/home/data/sleepStateExperiment_from_video/\")\n",
    "def apply_band_path_filter(mneR:mne.io.Raw):\n",
    "    sampling_rate = mneR.info[\"sfreq\"]\n",
    "    # Preapre an IIR filter\n",
    "    EEG_D = mne.filter.construct_iir_filter(\n",
    "        iir_params=dict(order=8, ftype='butter', output='sos'),\n",
    "        f_pass=[0.3, 120],\n",
    "        f_stop=None,  # Not used if ‘order’ is specified in iir_params\n",
    "        sfreq=sampling_rate,\n",
    "        btype='bandpass',\n",
    "        phase='zero',\n",
    "        return_copy=False\n",
    "    )\n",
    "    EMG_D = mne.filter.construct_iir_filter(\n",
    "        iir_params=dict(order=8, ftype='butter', output='sos'),\n",
    "        f_pass=[30, 9999],\n",
    "        f_stop=None,  # Not used if ‘order’ is specified in iir_params\n",
    "        sfreq=sampling_rate,\n",
    "        btype='bandpass',\n",
    "        phase='zero',\n",
    "        return_copy=False\n",
    "    )\n",
    "    # Filter data\n",
    "    mneR_butter = mneR.copy().filter(\n",
    "        l_freq=None, h_freq=None,  # For FIR filter\n",
    "        picks=\"eeg\",  # All channels\n",
    "        filter_length='auto',  # For FIR filter\n",
    "        l_trans_bandwidth='auto', h_trans_bandwidth='auto',  # For FIR filter\n",
    "        n_jobs=24,\n",
    "        method='iir',\n",
    "        iir_params=EEG_D,\n",
    "        phase='zero',\n",
    "        fir_window='hamming', fir_design='firwin',  # For FIR filter\n",
    "        skip_by_annotation=('edge', 'bad_acq_skip'),\n",
    "        pad='reflect_limited',  # For FIR filter\n",
    "        verbose=None\n",
    "    )\n",
    "    mneR_butter = mneR_butter.filter(\n",
    "        l_freq=None, h_freq=None,  # For FIR filter\n",
    "        picks=\"emg\",  # All channels\n",
    "        filter_length='auto',  # For FIR filter\n",
    "        l_trans_bandwidth='auto', h_trans_bandwidth='auto',  # For FIR filter\n",
    "        n_jobs=24,\n",
    "        method='iir',\n",
    "        iir_params=EMG_D,\n",
    "        phase='zero',\n",
    "        fir_window='hamming', fir_design='firwin',  # For FIR filter\n",
    "        skip_by_annotation=('edge', 'bad_acq_skip'),\n",
    "        pad='reflect_limited',  # For FIR filter\n",
    "        verbose=None\n",
    "    )\n",
    "    return mneR_butter\n",
    "\n",
    "\n",
    "def apply_notch_filter(mneR):\n",
    "    mneR_notch = mneR.notch_filter(\n",
    "        freqs=50,                # 自動検出\n",
    "        picks=[\"eeg\", \"emg\"],\n",
    "        method=\"spectrum_fit\",\n",
    "        filter_length=\"10s\",       # 推定安定化\n",
    "        mt_bandwidth=3.0,          # マルチテーパー帯域幅\n",
    "        p_value=0.05,\n",
    "        n_jobs=24\n",
    "    )\n",
    "    return mneR_notch\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e690fb42-b0f8-488b-b695-a4dfad612e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "mne_file_list = glob.glob(str(Path(DATA_FOLDER, \"analysis_tmp\", \"*.fif\")))\n",
    "mne_file_list = sorted(mne_file_list)\n",
    "for mneR_path in mne_file_list:\n",
    "    mneR_path = Path(mneR_path)\n",
    "    # skip if already exits\n",
    "    f_path = Path(\n",
    "        mneR_path.parent.parent,\n",
    "        \"analysis_tmp\", \"band_notch\", mneR_path.name)\n",
    "    if os.path.exists(f_path):\n",
    "        print(\"continue: \", f_path)\n",
    "        continue\n",
    "    # load file\n",
    "    mneR = mne.io.read_raw_fif(mneR_path, preload=True)\n",
    "    mneI = mneR.info.copy()\n",
    "\n",
    "    mneR_butter = apply_band_path_filter(mneR)\n",
    "    mneR_notch = apply_notch_filter(mneR_butter)\n",
    "\n",
    "    mneR_notch.save(f_path, overwrite=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47dd6270-895e-4d69-91fc-eac03eee8bca",
   "metadata": {},
   "source": [
    "## 6-3. Sleepens\n",
    "### 6-3-1. Run sleep Ensemble\n",
    "see `python/sleepens/mySleepEns.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a7be02-40c4-4350-bee2-ee36a7db6d8e",
   "metadata": {},
   "source": [
    "### 6-3-2. Check results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851e692e-ed72-42c4-914e-a933cf44cc4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to develop faster, use small file.\n",
    "    # Path(DATA_FOLDER, \"mneRaw\", \"20250917-001-0.fif\")\n",
    "file_name = \"20250917-001-0{}.fif\"\n",
    "\n",
    "orig_path_list = glob.glob(\n",
    "    str(Path(DATA_FOLDER,\"analysis_tmp\", \"band_notch\", \"20250917-001*-*-0.fif\"))\n",
    ")\n",
    "ens_path_list = glob.glob(\n",
    "    str(Path(DATA_FOLDER, \"sleepEnsOutput\", \"20250917-001*-*-0-predictions.fif\"))\n",
    ")\n",
    "\n",
    "orig_path_list.sort()\n",
    "ens_path_list.sort()\n",
    "\n",
    "for orig_path, mneR_ens_path in zip(orig_path_list, ens_path_list):\n",
    "    print(orig_path.split(\"/\")[-1], mneR_ens_path.split(\"/\")[-1])\n",
    "    mneR_orig = mne.io.read_raw_fif(\n",
    "        orig_path\n",
    "    )\n",
    "    mneR_ens = mne.io.read_raw_fif(\n",
    "        mneR_ens_path\n",
    "    )\n",
    "    # mneI_ens = mneR_ens.info.copy()\n",
    "    state = mneR_ens.pick(\"state\")\n",
    "    display_waveforms_with_states_simple(\n",
    "        mneR_orig,\n",
    "        state,\n",
    "        span=(450, 600),\n",
    "        unit=\"time\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d60e1d89-272d-4013-b91e-e65d6702e42a",
   "metadata": {},
   "source": [
    "## 6-4. Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a8d125-8b25-48c0-9585-1148c1e24d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_intervals(total_time_s: float):\n",
    "    segment_len = 180  # 3 min\n",
    "    step = 5           # every 5 sec\n",
    "    n_segments = 10\n",
    "\n",
    "    possible_starts = list(range(0, int(total_time_s - segment_len) + 1, step))\n",
    "    random.shuffle(possible_starts)\n",
    "\n",
    "    selected = []\n",
    "    for s in possible_starts:\n",
    "        if all(abs(s - prev_s) >= segment_len for prev_s in selected):\n",
    "            selected.append(s)\n",
    "        if len(selected) == n_segments:\n",
    "            break\n",
    "\n",
    "    selected.sort()\n",
    "    intervals = [(float(s), float(s + segment_len)) for s in selected]\n",
    "    return intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043f1788-edc5-49a3-b6e4-333db2e03a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_time = 7 * 3600 + 34 * 60 \n",
    "samples = sample_intervals(total_time)\n",
    "csv_path = Path(DATA_FOLDER, \"sleepEns_sampling\", \"sample_meta.csv\")\n",
    "with open(csv_path, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"id\", \"start\", \"end\"])\n",
    "    for i, (s, e) in enumerate(samples):\n",
    "        writer.writerow([i, s, e])\n",
    "print(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa9ccd6-153d-4306-91ed-32c8c28fbda5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "file_name = \"20250917-001{}.fif\"\n",
    "\n",
    "path_list = glob.glob(\n",
    "    str(Path(DATA_FOLDER, \"analysis_tmp\", \"band_notch\", file_name.format(\"*-*-*\")))\n",
    ")\n",
    "key = \"orig\"\n",
    "slice_idx = -6\n",
    "\n",
    "samples_df = pd.read_csv(DATA_FOLDER / \"sleepEns_sampling/sample_meta.csv\")\n",
    "samples = [tuple(row) for row in samples_df[[\"start\", \"end\"]].to_numpy()]\n",
    "\n",
    "\n",
    "\n",
    "path_list.sort()\n",
    "print(\"path_list: \")\n",
    "print(path_list)\n",
    "\n",
    "for i in range(6):\n",
    "    paths = path_list[4 * i:4 * i + 4]\n",
    "\n",
    "    raws = [mne.io.read_raw_fif(f, preload=True, verbose=True) for f in paths]\n",
    "\n",
    "    raw = mne.concatenate_raws(raws, verbose=True)\n",
    "    del raws\n",
    "\n",
    "    # save sampled span\n",
    "    name = paths[0].split(\"/\")[-1][:slice_idx]\n",
    "    for i, (tmin, tmax) in enumerate(samples):\n",
    "        sub = raw.copy().crop(tmin=float(tmin), tmax=float(tmax), include_tmax=True)\n",
    "        sub = sub.resample(sfreq=20000)\n",
    "        out_path = Path(DATA_FOLDER, \"sleepEns_sampling\", f\"{key}-{name}-sample{i}_raw.fif\")\n",
    "        sub.save(out_path.as_posix(), overwrite=True, verbose=True)\n",
    "    del sub\n",
    "    del raw\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93aa1706-f8ff-4c84-afd3-79af4938f8e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "file_name = \"20250917-001{}.fif\"\n",
    "path_list = glob.glob(\n",
    "    str(Path(DATA_FOLDER, \"sleepEnsOutput\", file_name.format(\"*-*-*-predictions\")))\n",
    ")\n",
    "key = \"pred\"\n",
    "slice_idx = -18\n",
    "\n",
    "samples_df = pd.read_csv(DATA_FOLDER / \"sleepEns_sampling/sample_meta.csv\")\n",
    "samples = [tuple(row) for row in samples_df[[\"start\", \"end\"]].to_numpy()]\n",
    "\n",
    "\n",
    "\n",
    "path_list.sort()\n",
    "print(\"path_list: \")\n",
    "print(path_list)\n",
    "\n",
    "for i in range(6):\n",
    "    paths = path_list[4 * i:4 * i + 4]\n",
    "\n",
    "    raws = [mne.io.read_raw_fif(f, preload=True, verbose=True) for f in paths]\n",
    "\n",
    "    raw = mne.concatenate_raws(raws, verbose=True)\n",
    "    del raws\n",
    "\n",
    "    # save sampled span\n",
    "    name = paths[0].split(\"/\")[-1][:slice_idx]\n",
    "    for i, (tmin, tmax) in enumerate(samples):\n",
    "        sub = raw.copy().crop(tmin=float(tmin), tmax=float(tmax), include_tmax=True)\n",
    "        sub = sub.resample(sfreq=20000)\n",
    "        out_path = Path(DATA_FOLDER, \"sleepEns_sampling\", f\"{key}-{name}-sample{i}_raw.fif\")\n",
    "        sub.save(out_path.as_posix(), overwrite=True, verbose=True)\n",
    "    del sub\n",
    "    del raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b0e1c2-c7e5-4fb7-8564-c61faf788f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hard-coded state mapping\n",
    "SCORE_MAP = {'AW': 0, 'QW': 1, 'NREM': 2, 'REM': 3}\n",
    "INV_SCORE_MAP = {v: k for k, v in SCORE_MAP.items()}\n",
    "_STATE_COLORS = {\n",
    "    0: (162, 53, 47),   # AW\n",
    "    1: (236, 197, 72),  # QW\n",
    "    2: (81, 158, 89),   # NREM\n",
    "    3: (52, 71, 113),   # REM\n",
    "}\n",
    "\n",
    "# Normalize to 0–1 for Matplotlib\n",
    "STATE_COLORS = {k: tuple(np.array(v, dtype=float) / 255.0) for k, v in _STATE_COLORS.items()}\n",
    "\n",
    "\n",
    "\n",
    "def display_waveforms_with_states_simple_for_sample(\n",
    "    raw: mne.io.Raw,\n",
    "    labels_raw: mne.io.Raw,     # 1-channel Raw; integer labels 0..3 per sample\n",
    "    title_text: str = \"\",\n",
    "    start: float = 0.0,         # 追加: データ先頭の実時刻（秒）\n",
    "    alpha_band: float = 0.15\n",
    "):\n",
    "    \"\"\"\n",
    "    Plot multi-channel waveforms and overlay 4-state categorical bands over the FULL duration.\n",
    "    X-axis is always HH:MM:SS. The first data point is displayed at time `start` (seconds).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    raw : mne.io.Raw\n",
    "        Source time-series to plot.\n",
    "    labels_raw : mne.io.Raw\n",
    "        1-channel Raw containing per-sample integer labels (0..3).\n",
    "        If sfreq differs from `raw`, it will be resampled to match.\n",
    "    title_text : str\n",
    "        Title for the figure.\n",
    "    start : float\n",
    "        X軸の開始時刻（秒）。データの0番目の要素がこの時刻として表示されます。\n",
    "    alpha_band : float\n",
    "        Alpha value for the background state bands.\n",
    "    \"\"\"\n",
    "    # コメント: 入力チェック（labels_raw は1ch）\n",
    "    if labels_raw.info[\"nchan\"] != 1:\n",
    "        raise ValueError(\"labels_raw must have exactly 1 channel (integer labels 0..3).\")\n",
    "\n",
    "    # コメント: サンプリング周波数を一致\n",
    "    sfreq = raw.info[\"sfreq\"]\n",
    "    labs = labels_raw.copy()\n",
    "    if not np.isclose(labs.info[\"sfreq\"], sfreq):\n",
    "        labs.resample(sfreq, npad=\"auto\")\n",
    "\n",
    "    # コメント: ラベルベクトルの取得と整形\n",
    "    lab = labs.get_data()[0]\n",
    "    lab = np.rint(lab).astype(int)\n",
    "    lab = np.clip(lab, 0, 3)\n",
    "\n",
    "    # コメント: 長さを raw に合わせる（最近傍）\n",
    "    if lab.shape[0] != raw.n_times:\n",
    "        idx = np.linspace(0, lab.shape[0] - 1, raw.n_times)\n",
    "        lab = lab[np.rint(idx).astype(int)]\n",
    "\n",
    "    # コメント: 全区間を取得（span 機能は削除）\n",
    "    data  = raw.get_data()\n",
    "    # コメント: x軸は常に「実時間（秒）」で、先頭に start を加算\n",
    "    times = raw.times + float(start)\n",
    "    labs_win = lab\n",
    "\n",
    "    # コメント: ラベルの連続区間を抽出\n",
    "    def contiguous_segments(lbl: np.ndarray):\n",
    "        if lbl.size == 0:\n",
    "            return []\n",
    "        edges = np.where(np.diff(lbl) != 0)[0] + 1\n",
    "        idxs = np.r_[0, edges, lbl.size]\n",
    "        return [(idxs[i], idxs[i+1], int(lbl[idxs[i]])) for i in range(len(idxs)-1)]\n",
    "\n",
    "    segs = contiguous_segments(labs_win)\n",
    "\n",
    "    # コメント: 図の準備\n",
    "    n_ch = raw.info[\"nchan\"]\n",
    "    fig_h = max(1.6, n_ch / 1.5)\n",
    "    fig, axes = plt.subplots(\n",
    "        nrows=n_ch, ncols=1,\n",
    "        figsize=(8.5, fig_h),\n",
    "        sharex=True, sharey=True,\n",
    "        gridspec_kw={'height_ratios': [1]*n_ch, 'hspace': 0.0}\n",
    "    )\n",
    "    if n_ch == 1:\n",
    "        axes = [axes]\n",
    "\n",
    "    # 軸位置\n",
    "    tick_step = 20.0\n",
    "    ticks = np.arange(times[0], times[-1] + 1e-9, tick_step)  # 開始時刻起点の 20 秒刻み\n",
    "\n",
    "    # コメント: x軸は常に HH:MM:SS 表示\n",
    "    def _sec_to_hhmmss(x, pos):\n",
    "        s = int(max(0, round(x)))\n",
    "        h = s // 3600\n",
    "        m = (s % 3600) // 60\n",
    "        ss = s % 60\n",
    "        return f\"{h:02d}:{m:02d}:{ss:02d}\"\n",
    "\n",
    "\n",
    "    # コメント: 軸範囲\n",
    "    if times.size == 0 or data.size == 0:\n",
    "        xlim = (0, 0); ylim = (-1, 1)\n",
    "    else:\n",
    "        xlim = (times[0], times[-1])\n",
    "        dmin, dmax = float(np.nanmin(data)), float(np.nanmax(data))\n",
    "        if dmin == dmax:\n",
    "            dmin, dmax = dmin - 1.0, dmax + 1.0\n",
    "        ylim = (dmin, dmax)\n",
    "    for ax in axes:\n",
    "        ax.xaxis.set_major_formatter(FuncFormatter(_sec_to_hhmmss))\n",
    "        ax.xaxis.set_major_locator(FixedLocator(ticks))\n",
    "        ax.set_xlim(*xlim)\n",
    "        ax.set_ylim(*ylim)\n",
    "\n",
    "\n",
    "    # コメント: 背景バンドと波形\n",
    "    for i, ax in enumerate(axes):\n",
    "        for s, e, lab_val in segs:\n",
    "            x0 = times[s]\n",
    "            x1 = times[e-1] if e-1 < times.size else times[-1]\n",
    "            ax.axvspan(x0, x1, color=STATE_COLORS[lab_val], alpha=alpha_band)\n",
    "\n",
    "        ax.plot(times, data[i], linewidth=0.35, color='k')\n",
    "\n",
    "        ax.spines.top.set_visible(False)\n",
    "        ax.spines.right.set_visible(False)\n",
    "        ax.set_yticks([])\n",
    "        ax.set_ylabel(\n",
    "            raw.ch_names[i],\n",
    "            rotation=0, ha='right', va='center',\n",
    "            rotation_mode='anchor'\n",
    "        )\n",
    "        if i == 0 and title_text:\n",
    "            ax.set_title(title_text)\n",
    "        if i == n_ch - 1:\n",
    "            ax.set_xlabel(\"Time [HH:MM:SS]\")\n",
    "        else:\n",
    "            ax.spines.bottom.set_visible(False)\n",
    "            ax.get_xaxis().set_visible(False)\n",
    "\n",
    "    # コメント: 凡例\n",
    "    handles = [Patch(color=STATE_COLORS[k], alpha=alpha_band, label=INV_SCORE_MAP[k]) for k in range(4)]\n",
    "    plt.subplots_adjust(right=0.80)\n",
    "    axes[0].legend(\n",
    "        handles=handles,\n",
    "        loc=\"upper left\",\n",
    "        bbox_to_anchor=(1.02, 1.0),\n",
    "        borderaxespad=0.0,\n",
    "        frameon=False,\n",
    "        title=\"State\"\n",
    "    )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99807957-5106-4ade-9879-f07d2d3498cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_path = DATA_FOLDER / \"sleepEns_sampling/orig-20250917-001HPC-1-sample5_raw.fif\"\n",
    "\n",
    "raw = mne.io.read_raw_fif(raw_path)\n",
    "\n",
    "label_path = DATA_FOLDER / \"sleepEns_sampling/pred-20250917-001HPC-1-sample5_raw.fif\"\n",
    "label_raw = mne.io.read_raw_fif(label_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf313d7c-2c85-498f-8cc6-8a5ccf0d4c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "eeg_type_list = [\"HPC-1\", \"HPC-2\", \"S1-1\", \"S1-2\", \"Skull-1\", \"Skull-2\"]\n",
    "base_path = str(DATA_FOLDER / \"sleepEns_sampling/{0}-20250917-001{1}-sample{2}_raw.fif\")\n",
    "\n",
    "sample_meta_path = DATA_FOLDER / \"sleepEns_sampling/sample_meta.csv\"\n",
    "sample_meta_df = pd.read_csv(sample_meta_path)\n",
    "for sample_idx in range(10):\n",
    "    for eeg_type in eeg_type_list:\n",
    "        start_time = sample_meta_df.iloc[sample_idx, 1]\n",
    "        _title = base_path.format(\"\", f\", EEG: {eeg_type},\", \": \"+str(sample_idx))\n",
    "        _title = _title.split(\"/\")[-1][1:].replace(\"_raw.fif\",\"\")\n",
    "        title = \"DATE: \" + _title.replace(\"-sample\", \" sample\")\n",
    "\n",
    "        data_path = base_path.format(\"orig\", eeg_type, sample_idx)\n",
    "        label_path = base_path.format(\"pred\", eeg_type, sample_idx,)\n",
    "\n",
    "        data_raw = mne.io.read_raw_fif(data_path, verbose=False)\n",
    "        label_raw = mne.io.read_raw_fif(label_path, verbose=False)\n",
    "\n",
    "        display_waveforms_with_states_simple_for_sample(\n",
    "            data_raw,\n",
    "            label_raw.pick(\"state\"),\n",
    "            start=start_time,\n",
    "            title_text=title\n",
    "        )\n",
    "del data_raw, label_raw,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50bbda92-9ee0-436c-912b-66923020b430",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_raw.info[\"sfreq\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ab0ebd-11b2-403c-aa44-8cd7943f7e5e",
   "metadata": {},
   "source": [
    "# 7. Check results\n",
    "## 7-1. check features one file\n",
    "data are saved on `DATA_FOLDER / spectral_band`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764ec0c5-ac7d-474a-bf26-4c0ad296962f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = DATA_FOLDER / \"spectral_band/20250917-001HPC-1-0_eeg_bands.npz\"\n",
    "npz = np.load(data_path, allow_pickle=True)\n",
    "print(\"Keys:\", list(npz.keys()))\n",
    "\n",
    "\n",
    "spec = npz[\"spec\"]\n",
    "freqs = npz[\"freqs\"]\n",
    "meta = npz[\"meta\"]\n",
    "\n",
    "print(\"spec shape:\", spec.shape)\n",
    "print(\"freqs:\", freqs)\n",
    "print(\"meta (head):\", meta[:10])  # 最初の10個だけ確認\n",
    "\n",
    "\n",
    "spec = npz[\"spec\"]\n",
    "freqs = npz[\"freqs\"]\n",
    "meta  = npz[\"meta\"]\n",
    "\n",
    "# コメント: spec → DataFrame化\n",
    "df = pd.DataFrame(spec, columns=freqs)\n",
    "display(df.head())\n",
    "display(df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4096a525-dd6b-4d9b-b0bd-638cf3d96102",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 4))\n",
    "\n",
    "# コメント: 各バンドを時系列でプロット\n",
    "df.plot(ax=ax, linewidth=0.8)\n",
    "\n",
    "sns.set(style='ticks', context='talk')#全体スタイルの簡易設定\n",
    "sns.despine()#XY軸のみ表示\n",
    "# コメント: 軸ラベルとタイトル\n",
    "ax.set_xlabel(\"Epoch index\")\n",
    "ax.set_ylabel(\"Power (a.u.)\")\n",
    "ax.set_title(\"Spectral Band Power Over Time\")\n",
    "# コメント: 凡例とレイアウト調整\n",
    "ax.legend(title=\"Band\")\n",
    "plt.tight_layout()\n",
    "sns.move_legend(ax, bbox_to_anchor=(1, 0.5), loc='center left', borderaxespad=1)#凡例位置\n",
    "# 表示（notebookで確認）\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41d0df0-23f3-4cf0-85df-c491d07606d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = Path(\"/home/data/sleepStateExperiment_from_video/\")\n",
    "raw = mne.io.read_raw_fif(DATA_FOLDER / \"sleepEnsOutput/20250917-001HPC-1-0-predictions.fif\")\n",
    "raw.get_channel_types()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb388a46-8b44-4ab9-94ed-2bb5202da572",
   "metadata": {},
   "outputs": [],
   "source": [
    "starts = raw.time_as_index(raw.annotations.onset)\n",
    "\n",
    "# コメント: state チャンネルからイベントコードを取得（0も含む）\n",
    "state = raw.get_data(picks=\"state\")[0]\n",
    "codes = state[starts].astype(int)\n",
    "\n",
    "# コメント: MNE形式のevents配列 [sample, 0, code]\n",
    "events = np.column_stack([starts, np.zeros_like(starts), codes])\n",
    "\n",
    "# コメント: eventコードをDataFrame化（indexは0,1,2,...）\n",
    "df_event = pd.DataFrame({\n",
    "    \"event\": events[:, 2].astype(int)\n",
    "})\n",
    "\n",
    "df_event.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a75d1ca-0c58-491b-81d3-00181d630006",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_event.shape)\n",
    "df_event.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b49183-f911-4af4-8b1b-036160e7f4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = DATA_FOLDER / \"spectral_band/20250917-001HPC-1-0_eeg_bands.npz\"\n",
    "npz = np.load(data_path, allow_pickle=True)\n",
    "print(\"Keys:\", list(npz.keys()))\n",
    "\n",
    "\n",
    "spec = npz[\"spec\"]\n",
    "freqs = npz[\"freqs\"]\n",
    "meta = npz[\"meta\"]\n",
    "\n",
    "print(\"spec shape:\", spec.shape)\n",
    "print(\"freqs:\", freqs)\n",
    "print(\"meta (head):\", meta[:10])  # 最初の10個だけ確認\n",
    "\n",
    "\n",
    "spec = npz[\"spec\"]\n",
    "freqs = npz[\"freqs\"]\n",
    "meta  = npz[\"meta\"]\n",
    "\n",
    "# コメント: spec → DataFrame化\n",
    "df_eeg = pd.DataFrame(spec, columns=freqs)\n",
    "display(df_eeg.head())\n",
    "display(df_eeg.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abda01dd-17ef-4a24-af1a-7b6146028614",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = Path(\"/home/data/sleepStateExperiment_from_video/\")\n",
    "data_path = DATA_FOLDER / \"spectral_band/20250917-001HPC-1-0_emg_entropy.npz\"\n",
    "npz = np.load(data_path, allow_pickle=True)\n",
    "print(\"Keys:\", list(npz.keys()))\n",
    "\n",
    "\n",
    "spec = npz[\"spec\"]\n",
    "freqs = npz[\"freqs\"]\n",
    "meta = npz[\"meta\"]\n",
    "\n",
    "print(\"spec shape:\", spec.shape)\n",
    "print(\"freqs:\", freqs)\n",
    "print(\"meta (head):\", meta[:10])  # 最初の10個だけ確認\n",
    "\n",
    "\n",
    "spec = npz[\"spec\"]\n",
    "freqs = npz[\"freqs\"]\n",
    "meta  = npz[\"meta\"]\n",
    "# コメント: spec → DataFrame化\n",
    "df_emg = pd.DataFrame(spec, columns=freqs)\n",
    "display(df_emg.head())\n",
    "display(df_emg.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c92ab9b-2359-4f95-84b3-c0db3bcc862c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_orig = pd.concat([df_eeg, df_emg, df_event],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec38a3b0-0a3e-4bc3-9288-5665edb71dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_orig.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c740ab8-2fbf-4f42-8e45-c8e8f7b596f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "df = df_orig.copy()\n",
    "\n",
    "# コメント: マッピング（必要なら併記）\n",
    "event_map_id2name = {0: 'AW', 1: 'QW', 2: 'NREM', 3: 'REM'}\n",
    "\n",
    "# コメント: 対象特徴量\n",
    "features = [\"DELTA\", \"THETA\", \"ALPHA\", \"BETA\", \"EMG ENTROPY\"]\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "df[features] = scaler.fit_transform(df[features])\n",
    "\n",
    "# コメント: 出力先ディレクトリ\n",
    "outdir = \"fig_event_stats\"\n",
    "os.makedirs(outdir, exist_ok=True)\n",
    "\n",
    "# コメント: 統計量（平均・分散）をevent×featureで計算してCSV保存（任意）\n",
    "stats_mean = df.groupby(\"event\")[features].mean()\n",
    "stats_var  = df.groupby(\"event\")[features].var(ddof=1)\n",
    "stats_std  = df.groupby(\"event\")[features].std(ddof=1)\n",
    "\n",
    "stats_mean.to_csv(os.path.join(outdir, \"stats_mean.csv\"))\n",
    "stats_var.to_csv(os.path.join(outdir, \"stats_variance.csv\"))\n",
    "stats_std.to_csv(os.path.join(outdir, \"stats_std.csv\"))\n",
    "\n",
    "sns.set(style='ticks', context='poster')#全体スタイルの簡易設定\n",
    "# コメント: 各eventごとに1枚ずつ図を作成（合計4枚）\n",
    "for ev_id in sorted(df[\"event\"].unique()):\n",
    "    ev_name = event_map_id2name.get(int(ev_id), str(ev_id))\n",
    "    sub = df[df[\"event\"] == ev_id]\n",
    "\n",
    "    # コメント: 各指標の平均と標準偏差（そのevent内での分布）\n",
    "    means = sub[features].mean().values\n",
    "    stds  = sub[features].std(ddof=1).values\n",
    "\n",
    "    # コメント: 図の作成（バー + エラーバー + 「＊」）\n",
    "    fig, ax = plt.subplots(figsize=(8, 5))\n",
    "    x = np.arange(len(features))\n",
    "    bars = ax.bar(x, means, yerr=stds, capsize=4)\n",
    "\n",
    "    sns.despine()#XY軸のみ表示\n",
    "\n",
    "    # コメント: 体裁\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(features, rotation=0)\n",
    "    ax.set_ylabel(\"Mean ± SD\")\n",
    "    ax.set_title(f\"{ev_name} title??\")\n",
    "    ax.grid(axis=\"y\", linestyle=\"--\", alpha=0.3)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    fig.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a93529-c6c0-41c8-8220-4aa8cc928284",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import itertools\n",
    "\n",
    "# コメント: 事前定義済み\n",
    "SCORE_MAP = {'AW': 0, 'QW': 1, 'NREM': 2, 'REM': 3}\n",
    "INV_SCORE_MAP = {v: k for k, v in SCORE_MAP.items()}\n",
    "_STATE_COLORS = {\n",
    "    0: (162, 53, 47),   # AW\n",
    "    1: (236, 197, 72),  # QW\n",
    "    2: (81, 158, 89),   # NREM\n",
    "    3: (52, 71, 113),   # REM\n",
    "}\n",
    "STATE_COLORS = {k: tuple(np.array(v, dtype=float)/255.0) for k, v in _STATE_COLORS.items()}\n",
    "\n",
    "# コメント: 特徴量のカラム\n",
    "features = [\"DELTA\", \"THETA\", \"ALPHA\", \"BETA\", \"EMG ENTROPY\"]\n",
    "\n",
    "# =========================================\n",
    "# 1) 各eventごとの平均・標準偏差を計算\n",
    "# =========================================\n",
    "stats_mean = df.groupby(\"event\")[features].mean()\n",
    "stats_std  = df.groupby(\"event\")[features].std(ddof=1)\n",
    "\n",
    "# =========================================\n",
    "# 2) 有意差の有無を簡易に判定（例: ANOVA）\n",
    "#    ※ 本格検定するなら多重比較に変更可能\n",
    "# =========================================\n",
    "pvals = {}\n",
    "for feat in features:\n",
    "    groups = [df.loc[df[\"event\"] == ev, feat].values for ev in sorted(SCORE_MAP.values())]\n",
    "    _, p = stats.f_oneway(*groups)\n",
    "    pvals[feat] = p\n",
    "\n",
    "# =========================================\n",
    "# 3) 描画 (1枚のfigureに4系列を重ね)\n",
    "# =========================================\n",
    "fig, ax = plt.subplots(figsize=(9, 5))\n",
    "x = np.arange(len(features))\n",
    "width = 0.18  # 各バーの幅\n",
    "offsets = np.linspace(-1.5*width, 1.5*width, 4)  # 4状態の横ずれ量\n",
    "\n",
    "for i, ev_id in enumerate(sorted(SCORE_MAP.values())):\n",
    "    means = stats_mean.loc[ev_id]\n",
    "    stds  = stats_std.loc[ev_id]\n",
    "    ax.bar(x + offsets[i],\n",
    "           means,\n",
    "           yerr=stds,\n",
    "           width=width,\n",
    "           capsize=3,\n",
    "           label=INV_SCORE_MAP[ev_id],\n",
    "           color=STATE_COLORS[ev_id],\n",
    "           edgecolor='black',\n",
    "           alpha=0.9)\n",
    "\n",
    "# =========================================\n",
    "# 4) 有意な特徴量に＊を付与\n",
    "# =========================================\n",
    "for i, feat in enumerate(features):\n",
    "    if pvals[feat] < 0.05:\n",
    "        ax.text(x[i], \n",
    "                max(stats_mean[feat]) + max(stats_std[feat])*0.5, \n",
    "                '*',\n",
    "                ha='center', va='bottom', fontsize=14, color='black')\n",
    "\n",
    "# =========================================\n",
    "# 5) 体裁調整\n",
    "# =========================================\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(features)\n",
    "ax.set_ylabel(\"Mean ± SD (normalized)\")\n",
    "ax.set_title(\"Feature comparison across sleep states\")\n",
    "ax.legend(title=\"Event\")\n",
    "ax.grid(axis=\"y\", linestyle=\"--\", alpha=0.3)\n",
    "fig.tight_layout()\n",
    "\n",
    "sns.despine()#XY軸のみ表示\n",
    "sns.move_legend(ax, bbox_to_anchor=(1, 0.5), loc='center left', borderaxespad=1)#凡例位置\n",
    "\n",
    "# 保存と表示\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac237d14-f3f4-4511-baad-0cf86948aa74",
   "metadata": {},
   "source": [
    "## 7-2. Check with all data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512e15ff-5e06-4cb7-bc3e-d9fbd0aa4529",
   "metadata": {},
   "source": [
    "### 7-2-1. Create merged data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e63db46-fcf6-4ded-b047-8b62a18ee0b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "DATA_FOLDER = Path(\"/home/data/sleepStateExperiment_from_video/\")\n",
    "\n",
    "files = sorted(glob.glob(str(DATA_FOLDER / \"sleepEnsOutput/20250917-001*-predictions.fif\")))\n",
    "df_list = []\n",
    "for pred_path in files:\n",
    "    pred_path = Path(pred_path)\n",
    "    eeg_path = DATA_FOLDER / f\"spectral_band/{pred_path.stem.replace('-predictions','')}_eeg_bands.npz\"\n",
    "    emg_path = DATA_FOLDER / f\"spectral_band/{pred_path.stem.replace('-predictions','')}_emg_entropy.npz\"\n",
    "\n",
    "\n",
    "    #  event\n",
    "    raw = mne.io.read_raw_fif(pred_path)\n",
    "    starts = raw.time_as_index(raw.annotations.onset)\n",
    "\n",
    "    # コメント: state チャンネルからイベントコードを取得（0も含む）\n",
    "    state = raw.get_data(picks=\"state\")[0]\n",
    "    codes = state[starts].astype(int)\n",
    "\n",
    "    # コメント: MNE形式のevents配列 [sample, 0, code]\n",
    "    events = np.column_stack([starts, np.zeros_like(starts), codes])\n",
    "\n",
    "    # コメント: eventコードをDataFrame化（indexは0,1,2,...）\n",
    "    df_event = pd.DataFrame({\n",
    "        \"event\": events[:, 2].astype(int)\n",
    "    })\n",
    "\n",
    "    # eeg\n",
    "    npz = np.load(eeg_path, allow_pickle=True)\n",
    "    df_eeg = pd.DataFrame(npz[\"spec\"], columns=npz[\"freqs\"])\n",
    "\n",
    "    npz = np.load(emg_path, allow_pickle=True)\n",
    "    df_emg = pd.DataFrame(npz[\"spec\"], columns=npz[\"freqs\"])\n",
    "\n",
    "    # # concat\n",
    "    df_orig = pd.concat([df_eeg, df_emg, df_event],axis=1)\n",
    "    df_list.append(df_orig)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b456a1-08db-467f-af32-b86792868e4e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for df in df_list:\n",
    "    display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42512c94-7ce7-49cb-96d4-4d356279efe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, eeg in enumerate([\"HPC-1\", \"HPC-2\", \"S1-1\", \"S1-2\", \"Skull-1\", \"Skull-2\"]):\n",
    "    for df in df_list[4 * i:4 * (i + 1)]:\n",
    "        df[\"eeg\"] = eeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41c6f2a-6be6-429d-a61c-dc9086aaccc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c266ddd7-eb82-43fd-9c7e-39d67eedcea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.concat(df_list, axis=0, ignore_index=True)\n",
    "df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600e2d76-7877-4c65-90d5-c80f694249f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.to_csv(DATA_FOLDER / \"spectral_band/concat/20250917-001.csv\")\n",
    "df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45bc9df-1590-4291-9af6-6ccd875adae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eeg = df_all.copy()\n",
    "\n",
    "# 「eeg」列の値を置換\n",
    "df_eeg[\"eeg\"] = df_eeg[\"eeg\"].replace({\n",
    "    \"HPC-1\": \"HPC\",\n",
    "    \"HPC-2\": \"HPC\",\n",
    "    \"S1-1\": \"S1\",\n",
    "    \"S1-2\": \"S1\",\n",
    "    \"Skull-1\": \"Skull\",\n",
    "    \"Skull-2\": \"Skull\"\n",
    "})\n",
    "\n",
    "display(df_eeg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f5e843-555f-4eb9-88f8-459148492622",
   "metadata": {},
   "source": [
    "### 7-2-2. Violin plot, U test + multiple testing correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab580763-834e-47b1-8e45-24f202e5c9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# コメント: マッピングと色\n",
    "SCORE_MAP = {'AW': 0, 'QW': 1, 'NR': 2, 'R': 3}\n",
    "INV_SCORE_MAP = {v: k for k, v in SCORE_MAP.items()}\n",
    "\n",
    "_STATE_COLORS = {\n",
    "    0: (162, 53, 47),   # AW\n",
    "    1: (236, 197, 72),  # QW\n",
    "    2: (81, 158, 89),   # NREM\n",
    "    3: (52, 71, 113),   # REM\n",
    "}\n",
    "STATE_COLORS = {k: tuple(np.array(v, dtype=float)/255.0) for k, v in _STATE_COLORS.items()}\n",
    "palette = {str(ev): STATE_COLORS[ev] for ev in sorted(STATE_COLORS.keys())}  # コメント: intキー\n",
    "\n",
    "features = [\"ALPHA\", \"BETA\", \"DELTA\", \"THETA\", \"EMG ENTROPY\"]\n",
    "TITLE_MAP = {\n",
    "    \"ALPHA\": \"α\",\n",
    "    \"BETA\": \"β\",\n",
    "    \"THETA\": \"θ\",\n",
    "    \"DELTA\": \"δ\",\n",
    "    \"EMG ENTROPY\": \"EMG Entropy\"\n",
    "}\n",
    "\n",
    "# コメント: アノテーション用ユーティリティ\n",
    "\n",
    "\n",
    "def add_sig_bracket(ax, x1, x2, y):\n",
    "    # コメント: x1とx2の上に括弧線とテキストを描く\n",
    "    ax.plot([x1, x1, x2, x2], [y, y*1.01, y*1.01, y], lw=1.2, c=\"k\")\n",
    "    ax.text((x1 + x2)/2, y, \"*\", ha='center', va='bottom', fontsize=12, color='k')\n",
    "\n",
    "\n",
    "\n",
    "order = sorted(SCORE_MAP.values())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "p_val = 0.01\n",
    "\n",
    "\n",
    "\n",
    "# EEGごとにデータを準備\n",
    "eeg_groups = list(df_eeg.groupby(\"eeg\"))\n",
    "\n",
    "n_rows = len(eeg_groups)\n",
    "n_cols = len(features)\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(19, 6.5 * n_rows), sharey=False)\n",
    "if n_rows == 1:\n",
    "    axes = np.expand_dims(axes, axis=0)\n",
    "\n",
    "\n",
    "for row_i, (eeg, df) in enumerate(eeg_groups):\n",
    "    for col_i, (ax, feature) in enumerate(zip(axes[row_i], features)):\n",
    "        sub = df[[\"event\", feature]]\n",
    "\n",
    "        sns.violinplot(\n",
    "            data=sub,\n",
    "            x=\"event\", y=feature,\n",
    "            palette=palette, inner=\"box\",\n",
    "            ax=ax,\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "        # --- U検定（全ペア比較） ---\n",
    "        pairs, pvals = [], []\n",
    "\n",
    "        unique_groups = sorted(sub[\"event\"].unique())\n",
    "\n",
    "        for i, g1 in enumerate(unique_groups):\n",
    "            for j, g2 in enumerate(unique_groups):\n",
    "                if j <= i:\n",
    "                    continue\n",
    "                vals1 = sub.loc[sub[\"event\"] == g1, feature]\n",
    "                vals2 = sub.loc[sub[\"event\"] == g2, feature]\n",
    "                _, p = mannwhitneyu(vals1, vals2, alternative=\"two-sided\")\n",
    "                pairs.append((g1, g2))\n",
    "                pvals.append(p)\n",
    "\n",
    "        # --- 多重検定補正（Holm） ---\n",
    "        rej, pvals_corr, _, _ = multipletests(pvals, alpha=p_val, method=\"holm\")\n",
    "\n",
    "        # --- 有意ペア抽出 ---\n",
    "        sig_pairs = []\n",
    "        for (g1, g2), p_corr, sig in zip(pairs, pvals_corr, rej):\n",
    "            if sig:\n",
    "                i, j = int(g1), int(g2)\n",
    "                sig_pairs.append((min(i, j), max(i, j), p_corr))\n",
    "\n",
    "        # --- アノテーション配置 ---\n",
    "        y_max = np.nanmax(sub[feature].values)\n",
    "        y_min = np.nanmin(sub[feature].values)\n",
    "        span = (y_max - y_min) if np.isfinite(y_max - y_min) and (y_max - y_min) > 0 else (abs(y_max) + 1.0)\n",
    "        base = y_max + 0.05 * span\n",
    "        step = 0.08 * span\n",
    "\n",
    "        for k, (i, j, p_adj) in enumerate(sorted(sig_pairs, key=lambda x: (x[1]-x[0], x[0], x[1]))):\n",
    "            x1 = order.index(i)\n",
    "            x2 = order.index(j)\n",
    "            y = base + k * step\n",
    "            add_sig_bracket(ax, x1, x2, y)\n",
    "\n",
    "        # === 軸タイトル・装飾 ===\n",
    "        ax.set_xticklabels([INV_SCORE_MAP[i] for i in order])\n",
    "        ax.set_xlabel(\"\")  # 軸ラベル自体は不要\n",
    "\n",
    "        ax.set_title(TITLE_MAP[feature])\n",
    "        if col_i == 0:\n",
    "            ax.set_ylabel(r\"Power [$\\mu V^2$/Hz]\")\n",
    "            ax.text(-0.5, 0.5, eeg, transform=ax.transAxes, rotation=90,\n",
    "            va='center', ha='right', fontweight='bold')\n",
    "        elif col_i == 4:\n",
    "            ax.set_ylabel(\"Entropy [a.u.]\")\n",
    "        else:\n",
    "            ax.set_ylabel(\"\")\n",
    "        sns.despine(ax=ax)\n",
    "\n",
    "# === 凡例と図全体調整 ===\n",
    "sns.set(style='ticks', context='poster')\n",
    "legend_handles = [\n",
    "    matplotlib.lines.Line2D([0], [0], linewidth=0, label=f'n={sub.shape[0]}, *Adjusted P < {p_val}'),\n",
    "]\n",
    "leg = fig.legend( handles=legend_handles)\n",
    "fig.suptitle(\"EEG (HPC, S1, Skull) Frequency Bands (α, β, θ, δ) and EMG Entropy\", y=1.01)\n",
    "\n",
    "sns.move_legend(fig, bbox_to_anchor=(1, 1), loc='upper right', borderaxespad=1) \n",
    "plt.tight_layout(w_pad=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532664ca-72db-4c81-a22e-9422b5eca4db",
   "metadata": {},
   "source": [
    "### 7-2-3 Violin plot, DUNN test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be06bc22-df78-4111-a7fa-1ce1a378466c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# コメント: マッピングと色\n",
    "SCORE_MAP = {'AW': 0, 'QW': 1, 'NR': 2, 'R': 3}\n",
    "INV_SCORE_MAP = {v: k for k, v in SCORE_MAP.items()}\n",
    "\n",
    "_STATE_COLORS = {\n",
    "    0: (162, 53, 47),   # AW\n",
    "    1: (236, 197, 72),  # QW\n",
    "    2: (81, 158, 89),   # NREM\n",
    "    3: (52, 71, 113),   # REM\n",
    "}\n",
    "STATE_COLORS = {k: tuple(np.array(v, dtype=float)/255.0) for k, v in _STATE_COLORS.items()}\n",
    "palette = {str(ev): STATE_COLORS[ev] for ev in sorted(STATE_COLORS.keys())}  # コメント: intキー\n",
    "\n",
    "features = [\"ALPHA\", \"BETA\", \"DELTA\", \"THETA\", \"EMG ENTROPY\"]\n",
    "TITLE_MAP = {\n",
    "    \"ALPHA\": \"α\",\n",
    "    \"BETA\": \"β\",\n",
    "    \"THETA\": \"θ\",\n",
    "    \"DELTA\": \"δ\",\n",
    "    \"EMG ENTROPY\": \"EMG Entropy\"\n",
    "}\n",
    "\n",
    "# コメント: アノテーション用ユーティリティ\n",
    "\n",
    "\n",
    "def add_sig_bracket(ax, x1, x2, y):\n",
    "    # コメント: x1とx2の上に括弧線とテキストを描く\n",
    "    ax.plot([x1, x1, x2, x2], [y, y*1.01, y*1.01, y], lw=1.2, c=\"k\")\n",
    "    ax.text((x1 + x2)/2, y, \"*\", ha='center', va='bottom', fontsize=12, color='k')\n",
    "\n",
    "\n",
    "\n",
    "order = sorted(SCORE_MAP.values())\n",
    "\n",
    "\n",
    "\n",
    "p_val = 0.05\n",
    "\n",
    "\n",
    "\n",
    "# EEGごとにデータを準備\n",
    "eeg_groups = list(df_eeg.groupby(\"eeg\"))\n",
    "\n",
    "n_rows = len(eeg_groups)\n",
    "n_cols = len(features)\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(18, 6.5 * n_rows), sharey=False)\n",
    "if n_rows == 1:\n",
    "    axes = np.expand_dims(axes, axis=0)\n",
    "\n",
    "\n",
    "for row_i, (eeg, df) in enumerate(eeg_groups):\n",
    "    for col_i, (ax, feature) in enumerate(zip(axes[row_i], features)):\n",
    "        sub = df[[\"event\", feature]]\n",
    "\n",
    "        sns.violinplot(\n",
    "            data=sub,\n",
    "            x=\"event\", y=feature,\n",
    "            palette=palette, inner=\"box\",\n",
    "            ax=ax,\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "        # --- Dunn検定（Holm補正） ---\n",
    "        dunn_res = sp.posthoc_dunn(\n",
    "            sub, \n",
    "            val_col=feature, \n",
    "            group_col=\"event\", \n",
    "            p_adjust=\"holm\"\n",
    "        )\n",
    "\n",
    "        # --- 有意ペア抽出 ---\n",
    "        sig_pairs = []\n",
    "        for i, g1 in enumerate(dunn_res.index):\n",
    "            for j, g2 in enumerate(dunn_res.columns):\n",
    "                if j <= i:\n",
    "                    continue\n",
    "                p_adj = dunn_res.iloc[i, j]\n",
    "                if p_adj < p_val:\n",
    "                    sig_pairs.append((int(g1), int(g2), p_adj))\n",
    "\n",
    "        # --- アノテーション配置 ---\n",
    "        y_max = np.nanmax(sub[feature].values)\n",
    "        y_min = np.nanmin(sub[feature].values)\n",
    "        span = (y_max - y_min) if np.isfinite(y_max - y_min) and (y_max - y_min) > 0 else (abs(y_max) + 1.0)\n",
    "        base = y_max + 0.05 * span\n",
    "        step = 0.08 * span\n",
    "\n",
    "        for k, (i, j, p_adj) in enumerate(sorted(sig_pairs, key=lambda x: (x[1]-x[0], x[0], x[1]))):\n",
    "            x1 = order.index(i)\n",
    "            x2 = order.index(j)\n",
    "            y = base + k * step\n",
    "            add_sig_bracket(ax, x1, x2, y)\n",
    "\n",
    "        # === 軸タイトル・装飾 ===\n",
    "        ax.set_xticklabels([INV_SCORE_MAP[i] for i in order])\n",
    "        ax.set_xlabel(\"\")  # 軸ラベル自体は不要\n",
    "\n",
    "        if row_i == 0:\n",
    "            ax.set_title(TITLE_MAP[feature])\n",
    "        if col_i == 0:\n",
    "            ax.set_ylabel(r\"Power [$\\mu V^2$/Hz]\")\n",
    "            ax.text(-0.5, 0.5, eeg, transform=ax.transAxes, rotation=90,\n",
    "            va='center', ha='right', fontweight='bold')\n",
    "        elif col_i == 4:\n",
    "            ax.set_ylabel(\"Entropy [a.u.]\")\n",
    "        else:\n",
    "            ax.set_ylabel(\"\")\n",
    "        sns.despine(ax=ax)\n",
    "\n",
    "# === 凡例と図全体調整 ===\n",
    "sns.set(style='ticks', context='poster')\n",
    "legend_handles = [\n",
    "    matplotlib.lines.Line2D([0], [0], linewidth=0, label=f'n={sub.shape[0]}, *Adjusted P < {p_val}'),\n",
    "]\n",
    "leg = fig.legend( handles=legend_handles)\n",
    "fig.suptitle(\"EEG (HPC, S1, Skull) Frequency Bands (α, β, θ, δ) and EMG Entropy\", y=1.01)\n",
    "\n",
    "sns.move_legend(fig, bbox_to_anchor=(1, 1), loc='upper right', borderaxespad=1) \n",
    "plt.tight_layout(w_pad=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c284f50c-b982-4521-91c4-37ad90ff1561",
   "metadata": {},
   "source": [
    "### 7-2-4. Heat map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b54b8f-0051-4e0d-9551-72cc110948e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.read_csv(DATA_FOLDER / \"spectral_band/concat/20250917-001.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b244d6-fe63-4185-b0ae-9c611cf224b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_event = df_all.loc[:,[\"event\",\"eeg\"]]\n",
    "df_event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f69642-b542-46fc-a083-8e055a49fed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "for name, sub in df_event.groupby(\"eeg\"):\n",
    "    sub = sub.reset_index(drop=True).copy()\n",
    "    sub.rename(columns={\"event\": f\"event_{name}\"}, inplace=True)\n",
    "    dfs.append(sub[[f\"event_{name}\"]])  # event列だけ残す\n",
    "\n",
    "# インデックスで横結合（行数が異なる場合はNaN補完）\n",
    "df_wide = pd.concat(dfs, axis=1)\n",
    "df_wide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c32991-ad3c-4ce5-a37d-4d3b34c106cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = df_wide.columns\n",
    "\n",
    "n_rows = len(df_wide)   # サンプル数\n",
    "n_cols = len(cols)      # チャンネル数\n",
    "\n",
    "# コメント: 出力配列を初期化（bool型, shape=(n_cols, n_cols, n_rows)）\n",
    "matches = np.zeros((n_cols, n_cols, n_rows), dtype=bool)\n",
    "\n",
    "# コメント: 各ペア間で event 値の一致を判定\n",
    "for i, col_i in enumerate(cols):\n",
    "    for j, col_j in enumerate(cols):\n",
    "        # 各サンプルごとに一致しているか（Series同士の比較）\n",
    "        matches[i, j, :] = (df_wide[col_i].values == df_wide[col_j].values)\n",
    "\n",
    "# コメント: 結果確認\n",
    "print(matches.shape)  # (n_cols, n_cols, n_rows)\n",
    "print(matches.dtype)  # bool\n",
    "\n",
    "# コメント: 一致率を算出する場合（オプション）\n",
    "agreement = matches.mean(axis=2)\n",
    "df_agree = pd.DataFrame(agreement, index=cols, columns=cols)\n",
    "print(df_agree.round(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f234f7-4350-4b8e-97fa-076189be98e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_matches = matches.sum(axis=2, keepdims=False)\n",
    "sum_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f0c8a7-f4be-4822-ac50-45f7b9b7a832",
   "metadata": {},
   "outputs": [],
   "source": [
    "(sum_matches / df_wide.shape[0]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4df3ccc-cf1c-4df0-96b9-4a753c51feb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from statsmodels.stats.proportion import proportion_confint\n",
    "\n",
    "# 前提: matches.shape = (n_col, n_col, n_row), keepdims=False で作った sum_matches を使う\n",
    "# sum_matches = matches.sum(axis=2)  # shape = (n_col, n_col)\n",
    "\n",
    "n_row = df_wide.shape[0]\n",
    "n_col = sum_matches.shape[0]\n",
    "\n",
    "# 平均一致率（質問の式と同じ）\n",
    "p_mean = (sum_matches / n_row).mean()\n",
    "\n",
    "# Wilson法のための k, n を定義（全ペア×全サンプルでの一致総数 / 試行総数）\n",
    "k = int(sum_matches.sum())                 # 一致の総数（Trueの総数）\n",
    "n = int(n_row * (n_col * n_col))           # 試行総数（各サンプルで n_col^2 個の比較）\n",
    "\n",
    "# Wilson 95% CI\n",
    "lo, hi = proportion_confint(k, n, alpha=0.05, method=\"wilson\")\n",
    "p = k / n\n",
    "\n",
    "name = \"ALL\"\n",
    "print(f\"{name:8s}: p={p:.3f}, 95% CI=({lo:.3f}, {hi:.3f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d704a03-9527-484f-9c4a-f022885ec59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 対角線と重複除いたパターン\n",
    "# sum_matches: shape = (n_col, n_col)\n",
    "n_row = df_wide.shape[0]\n",
    "n_col = sum_matches.shape[0]\n",
    "\n",
    "# コメント: 対角を除いた上三角（または下三角）インデックスを取得\n",
    "upper_idx = np.triu_indices(n_col, k=1)\n",
    "print(upper_idx)\n",
    "# コメント: 対角除外で有効な一致数と比較数を抽出\n",
    "valid_sum = sum_matches[upper_idx]\n",
    "print(valid_sum)\n",
    "k = int(valid_sum.sum())                 # 一致の総数\n",
    "n = int(len(valid_sum) * n_row)          # 試行総数（ペア数 × サンプル数）\n",
    "\n",
    "# コメント: 平均一致率\n",
    "p_hat = k / n\n",
    "\n",
    "# Wilson法の信頼区間\n",
    "ci_low, ci_high = proportion_confint(k, n, alpha=0.05, method=\"wilson\")\n",
    "\n",
    "print(f\"ALL(offdiag): p={p_hat:.3f}, 95% CI=({ci_low:.3f}, {ci_high:.3f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25ca375-3d50-4cf4-8a4c-98e3a61267d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agree = pd.DataFrame(\n",
    "    sum_matches / df_wide.shape[0],\n",
    "    index=cols,\n",
    "    columns=cols\n",
    ")\n",
    "df_agree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a474378-0b9f-4763-8ff2-d27707cf80be",
   "metadata": {},
   "outputs": [],
   "source": [
    "_dic = {col:col[6:] for col in df_agree.columns}\n",
    "df_tmp = df_agree.copy().rename(columns=_dic, index=_dic)\n",
    "sns.set(style='ticks', context='talk')#全体スタイルの簡易設定\n",
    "sns.heatmap(df_tmp, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0294afa6-fbb0-4b48-aa6f-ce0976bdd382",
   "metadata": {},
   "source": [
    "### 7-2-5. Check with bideo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf817b11-880e-4c6a-b193-57f749c45f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 対角線と重複/同じタイプのEEGチャンネルを除いたパターン\n",
    "# sum_matches: shape = (n_col, n_col)\n",
    "n_row = df_wide.shape[0]\n",
    "n_col = sum_matches.shape[0]\n",
    "cols = df_wide.columns\n",
    "_upper_idx = np.triu_indices(n_col, k=1)\n",
    "upper_idx = [[], []]\n",
    "print(_upper_idx)\n",
    "for i, j in zip(*_upper_idx):\n",
    "    if cols[i][:-1] != cols[j][:-1]:\n",
    "        upper_idx[0].append(i)\n",
    "        upper_idx[1].append(j)\n",
    "upper_idx = tuple([np.array(lis) for lis in upper_idx])\n",
    "print(upper_idx)\n",
    "\n",
    "# コメント: 対角除外で有効な一致数と比較数を抽出\n",
    "valid_sum = sum_matches[upper_idx]\n",
    "print(valid_sum)\n",
    "k = int(valid_sum.sum())                 # 一致の総数\n",
    "n = int(len(valid_sum) * n_row)          # 試行総数（ペア数 × サンプル数）\n",
    "\n",
    "# コメント: 平均一致率\n",
    "p_hat = k / n\n",
    "\n",
    "# Wilson法の信頼区間\n",
    "ci_low, ci_high = proportion_confint(k, n, alpha=0.05, method=\"wilson\")\n",
    "\n",
    "print(f\"ALL(offdiag): p={p_hat:.3f}, 95% CI=({ci_low:.3f}, {ci_high:.3f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27a09c7-76e7-4c42-9f12-6858557a7873",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "row_all_equal = (df_wide.nunique(axis=1) == 1)  # bool Series\n",
    "\n",
    "# コメント: 合計と比率\n",
    "agree_count = int(row_all_equal.sum())\n",
    "agree_ratio = agree_count / len(df_wide)\n",
    "\n",
    "print(f\"全列一致の行数: {agree_count}\")\n",
    "print(f\"全列一致の比率: {agree_ratio:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ffca2c-daed-4d19-9835-960438ece643",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from statsmodels.stats.proportion import proportion_confint\n",
    "import numpy as np\n",
    "\n",
    "# データ\n",
    "hpc_1   = [4, 1, 2, 0, 1, 3, 0, 0, 0, 0]\n",
    "hpc_2   = [4, 1, 2, 0, 1, 3, 0, 0, 0, 0]\n",
    "s1_1    = [3, 1, 2, 0, 1, 4, 0, 0, 0, 0]\n",
    "s1_2    = [4, 1, 2, 0, 1, 5, 0, 0, 0, 0]\n",
    "skull_1 = [6, 1, 2, 0, 1, 4, 0, 0, 0, 0]\n",
    "skull_2 = [5, 1, 2, 0, 1, 3, 0, 0, 0, 0]\n",
    "\n",
    "groups = {\n",
    "    \"HPC_1\": hpc_1,\n",
    "    \"HPC_2\": hpc_2,\n",
    "    \"S1_1\": s1_1,\n",
    "    \"S1_2\": s1_2,\n",
    "    \"Skull_1\": skull_1,\n",
    "    \"Skull_2\": skull_2,\n",
    "}\n",
    "\n",
    "n_total = 36  # 各試行でのエポック数\n",
    "\n",
    "results = {}\n",
    "for name, counts in groups.items():\n",
    "    k = np.sum(counts)\n",
    "    n = len(counts) * n_total\n",
    "    p_hat = k / n\n",
    "\n",
    "    # Wilson法\n",
    "    ci_low, ci_high = proportion_confint(k, n, alpha=0.05, method=\"wilson\")\n",
    "    results[name] = (p_hat, ci_low, ci_high)\n",
    "\n",
    "for name, (p, lo, hi) in results.items():\n",
    "    print(f\"{name:8s}: p={p:.3f}, 95% CI=({lo:.3f}, {hi:.3f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6915680d-7494-44f6-b14b-b4636fbe44ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = list(results.keys())\n",
    "probs = [results[n][0] for n in names]\n",
    "lower = [results[n][0] - results[n][1] for n in names]  # 下側誤差\n",
    "upper = [results[n][2] - results[n][0] for n in names]  # 上側誤差\n",
    "\n",
    "x = np.arange(len(names))\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "ax.bar(x, probs, color=\"skyblue\", yerr=[lower, upper], capsize=5)\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(names, rotation=45, ha=\"right\")\n",
    "ax.set_ylabel(\"Misclassification rate\")\n",
    "\n",
    "# y軸範囲調整\n",
    "ax.set_ylim(0, max(np.array(probs) + np.array(upper)) * 1.2)\n",
    "\n",
    "# === 凡例のような注釈を右上に追加 ===\n",
    "ax.text(\n",
    "    0.95, 0.95, \"mean ± 95% CI (n=360)\",\n",
    "    transform=ax.transAxes,\n",
    "    ha=\"right\", va=\"top\", fontsize=24\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "sns.despine()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17dc7d34-e9fe-431d-a13c-24222c2849bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4e84d1-9bdd-43b6-bccf-ec774fddde14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
